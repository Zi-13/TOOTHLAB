import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import json
import sqlite3
import os
import argparse
import glob
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Tuple
# é«˜æ€§èƒ½åº“å¯¼å…¥
from scipy import ndimage
from skimage.segmentation import watershed
from skimage.feature import peak_local_max
from skimage.morphology import remove_small_objects, binary_opening, disk
from skimage.measure import label, regionprops
from scipy.ndimage import distance_transform_edt

# === 1. ç§»æ¤ç‰¹å¾æå–ç›¸å…³ç±» ===
import logging
from numpy.linalg import lstsq
from sklearn.metrics.pairwise import cosine_similarity

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

PHOTO_PATH = r'c:\Users\Jason\Desktop\tooth\Tooth_5.png'

class FourierAnalyzer:import cv2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import json
import sqlite3
import os
import argparse
import glob
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Tuple
# é«˜æ€§èƒ½åº“å¯¼å…¥
from scipy import ndimage
from skimage.segmentation import watershed
from skimage.feature import peak_local_max
from skimage.morphology import remove_small_objects, binary_opening, disk
from skimage.measure import label, regionprops
from scipy.ndimage import distance_transform_edt

# === 1. ç§»æ¤ç‰¹å¾æå–ç›¸å…³ç±» ===
import logging
from numpy.linalg import lstsq
from sklearn.metrics.pairwise import cosine_similarity

# === æ–°å¢ï¼šæ ‡å®šç›¸å…³å¯¼å…¥ ===
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

PHOTO_PATH = r'F:\python\.vscode\toothIDMatch\images\Tooth_10.png'

# ===== å°ºåº¦æ ‡å®šç›¸å…³ç±»å®šä¹‰ï¼ˆç§»æ¤å¹¶é€‚é…é•¿æ–¹å½¢æ ‡å®šç‰©ï¼‰=====
@dataclass
class ReferenceObject:
    """å‚è€ƒç‰©è§„æ ¼å®šä¹‰ - é€‚é…134mmÃ—9mmé•¿æ–¹å½¢æ ‡å®šç‰©"""
    size_mm: Tuple[float, float] = (134.0, 9.0)  # (é•¿åº¦, å®½åº¦) å•ä½ï¼šmm
    color_hsv_range: Dict = None
    
    def __post_init__(self):
        if self.color_hsv_range is None:
            # é»˜è®¤çº¢è‰²èŒƒå›´ï¼Œå¯æ ¹æ®å®é™…æ ‡å®šç‰©é¢œè‰²è°ƒæ•´
            self.color_hsv_range = {
                'lower': np.array([0, 144, 169]),
                'upper': np.array([15, 255, 255]),
                'lower2': np.array([165, 144, 169]),
                'upper2': np.array([180, 255, 255])
            }

@dataclass
class CalibrationResult:
    """æ ‡å®šç»“æœæ•°æ®ç±»"""
    pixel_per_mm: float
    reference_pixel_size: Tuple[float, float]  # (é•¿è¾¹åƒç´ , çŸ­è¾¹åƒç´ )
    reference_position: Tuple[int, int, int, int]
    confidence: float
    long_edge_mm: float = 134.0  # é•¿è¾¹ç‰©ç†å°ºå¯¸
    short_edge_mm: float = 9.0   # çŸ­è¾¹ç‰©ç†å°ºå¯¸
    error_message: str = ""

class ReferenceDetector:
    """å‚è€ƒç‰©æ£€æµ‹å™¨ - ä¸“é—¨é’ˆå¯¹134mmÃ—9mmé•¿æ–¹å½¢æ ‡å®šç‰©"""
    
    def __init__(self, reference_obj: ReferenceObject):
        self.reference_obj = reference_obj
        
    def detect_reference_object(self, image: np.ndarray) -> CalibrationResult:
        """æ£€æµ‹å›¾åƒä¸­çš„é•¿æ–¹å½¢å‚è€ƒç‰©å¹¶è®¡ç®—æ ‡å®šå‚æ•°"""
        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            mask = self._create_color_mask(hsv)
            mask = self._clean_mask(mask)
            
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if not contours:
                return CalibrationResult(0, (0, 0), (0, 0, 0, 0), 0, error_message="æœªæ£€æµ‹åˆ°å‚è€ƒç‰©é¢œè‰²")
            
            best_contour = self._find_best_reference_contour(contours)
            
            if best_contour is None:
                return CalibrationResult(0, (0, 0), (0, 0, 0, 0), 0, error_message="æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é•¿æ–¹å½¢å‚è€ƒç‰©")
            
            return self._calculate_calibration(best_contour)
            
        except Exception as e:
            logger.error(f"å‚è€ƒç‰©æ£€æµ‹å¤±è´¥: {e}")
            return CalibrationResult(0, (0, 0), (0, 0, 0, 0), 0, error_message=f"æ£€æµ‹å¼‚å¸¸: {str(e)}")
    
    def _create_color_mask(self, hsv: np.ndarray) -> np.ndarray:
        """åˆ›å»ºé¢œè‰²æ©ç """
        color_range = self.reference_obj.color_hsv_range
        mask1 = cv2.inRange(hsv, color_range['lower'], color_range['upper'])
        mask2 = cv2.inRange(hsv, color_range['lower2'], color_range['upper2'])
        return cv2.bitwise_or(mask1, mask2)
    
    def _clean_mask(self, mask: np.ndarray) -> np.ndarray:
        """æ¸…ç†æ©ç å™ªå£°"""
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        return mask
    
    def _find_best_reference_contour(self, contours: List) -> Optional[np.ndarray]:
        """æ‰¾åˆ°æœ€ä½³çš„é•¿æ–¹å½¢å‚è€ƒç‰©è½®å»“"""
        candidates = []
        
        for contour in contours:
            area = cv2.contourArea(contour)
            if area < 500:  # é•¿æ–¹å½¢é¢ç§¯é˜ˆå€¼æ¯”æ­£æ–¹å½¢å¤§
                continue
            
            features = self._analyze_contour_shape(contour)
            score = self._evaluate_rectangle_candidate(features)
            
            if score > 0.6:  # é•¿æ–¹å½¢æ£€æµ‹è¦æ±‚æ›´é«˜çš„åˆ†æ•°
                candidates.append((contour, score, features))
        
        if not candidates:
            return None
        
        best_contour, best_score, best_features = max(candidates, key=lambda x: x[1])
        logger.info(f"ğŸ¯ æ‰¾åˆ°æœ€ä½³é•¿æ–¹å½¢å€™é€‰ï¼Œè¯„åˆ†: {best_score:.3f}")
        return best_contour
    
    def _analyze_contour_shape(self, contour: np.ndarray) -> Dict:
        """åˆ†æè½®å»“å½¢çŠ¶ç‰¹å¾"""
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)
        
        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = max(w, h) / min(w, h) if min(w, h) > 0 else 0  # é•¿è¾¹/çŸ­è¾¹
        
        rect_area = w * h
        rectangularity = area / rect_area if rect_area > 0 else 0
        
        circularity = (4 * np.pi * area) / (perimeter * perimeter) if perimeter > 0 else 0
        
        hull = cv2.convexHull(contour)
        hull_area = cv2.contourArea(hull)
        solidity = area / hull_area if hull_area > 0 else 0
        
        return {
            'area': area,
            'perimeter': perimeter,
            'aspect_ratio': aspect_ratio,
            'rectangularity': rectangularity,
            'circularity': circularity,
            'solidity': solidity,
            'bounding_rect': (x, y, w, h),
            'long_edge': max(w, h),
            'short_edge': min(w, h)
        }
    
    def _evaluate_rectangle_candidate(self, features: Dict) -> float:
        """è¯„ä¼°é•¿æ–¹å½¢å‚è€ƒç‰©å€™é€‰çš„è´¨é‡"""
        score = 0.0
        
        # é•¿æ–¹å½¢æ¯”ä¾‹æ£€æŸ¥ï¼š134:9 = 16.75:1
        aspect_ratio = features['aspect_ratio']
        expected_ratio = 134.0 / 9.0  # 16.75
        ratio_error = abs(aspect_ratio - expected_ratio) / expected_ratio
        
        if ratio_error < 0.1:  # è¯¯å·®å°äº10%
            score += 0.4
        elif ratio_error < 0.2:  # è¯¯å·®å°äº20%
            score += 0.2
        
        # çŸ©å½¢åº¦æ£€æŸ¥
        rectangularity = features['rectangularity']
        if rectangularity > 0.8:
            score += 0.3
        elif rectangularity > 0.7:
            score += 0.2
        
        # å®ä½“åº¦æ£€æŸ¥
        solidity = features['solidity']
        if solidity > 0.85:
            score += 0.2
        elif solidity > 0.75:
            score += 0.1
        
        # é¢ç§¯åˆç†æ€§æ£€æŸ¥
        area = features['area']
        if 500 <= area <= 20000:  # é•¿æ–¹å½¢é¢„æœŸé¢ç§¯èŒƒå›´
            score += 0.1
        
        logger.debug(f"é•¿æ–¹å½¢è¯„ä¼°: æ¯”ä¾‹={aspect_ratio:.2f}(æœŸæœ›{expected_ratio:.2f}), "
                    f"çŸ©å½¢åº¦={rectangularity:.3f}, å®ä½“åº¦={solidity:.3f}, æ€»åˆ†={score:.3f}")
        
        return min(score, 1.0)
    
    def _calculate_calibration(self, contour: np.ndarray) -> CalibrationResult:
        """è®¡ç®—é•¿æ–¹å½¢æ ‡å®šå‚æ•°"""
        x, y, w, h = cv2.boundingRect(contour)
        
        # ç¡®å®šé•¿è¾¹å’ŒçŸ­è¾¹
        long_edge_pixels = max(w, h)
        short_edge_pixels = min(w, h)
        
        # ä½¿ç”¨é•¿è¾¹ä½œä¸ºä¸»è¦æ ‡å®šåŸºå‡†
        pixel_per_mm = long_edge_pixels / self.reference_obj.size_mm[0]  # é•¿è¾¹ï¼š134mm
        
        # äº¤å‰éªŒè¯ï¼šçŸ­è¾¹åº”è¯¥çº¦ç­‰äº 9 * pixel_per_mm
        expected_short_edge = self.reference_obj.size_mm[1] * pixel_per_mm  # 9 * pixel_per_mm
        short_edge_error = abs(short_edge_pixels - expected_short_edge) / expected_short_edge
        
        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºé•¿å®½æ¯”å’Œäº¤å‰éªŒè¯ï¼‰
        aspect_ratio = long_edge_pixels / short_edge_pixels if short_edge_pixels > 0 else 0
        expected_aspect = self.reference_obj.size_mm[0] / self.reference_obj.size_mm[1]
        aspect_error = abs(aspect_ratio - expected_aspect) / expected_aspect
        
        # ç»¼åˆç½®ä¿¡åº¦è®¡ç®—
        confidence = 1.0 - (aspect_error * 0.6 + short_edge_error * 0.4)
        confidence = max(0.0, min(1.0, confidence))
        
        # æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯
        logger.info(f"ğŸ“ é•¿æ–¹å½¢æ ‡å®šç‰©æ£€æµ‹ç»“æœ:")
        logger.info(f"   æ£€æµ‹ä½ç½®: ({x}, {y}), å°ºå¯¸: {w}Ã—{h} åƒç´ ")
        logger.info(f"   é•¿è¾¹: {long_edge_pixels} px (å¯¹åº” 134 mm)")
        logger.info(f"   çŸ­è¾¹: {short_edge_pixels} px (å¯¹åº” 9 mm)")
        logger.info(f"   æ¯”ä¾‹ç³»æ•°: {pixel_per_mm:.4f} px/mm")
        logger.info(f"   å®é™…æ¯”ä¾‹: {aspect_ratio:.2f} (æœŸæœ›: {expected_aspect:.2f})")
        logger.info(f"   çŸ­è¾¹éªŒè¯è¯¯å·®: {short_edge_error:.3f}")
        logger.info(f"   ç½®ä¿¡åº¦: {confidence:.3f}")
        logger.info(f"   é¢ç§¯æ¢ç®—å…¬å¼: åƒç´ é¢ç§¯ Ã· {pixel_per_mm:.1f}Â² = çœŸå®é¢ç§¯(mmÂ²)")
        
        return CalibrationResult(
            pixel_per_mm=pixel_per_mm,
            reference_pixel_size=(long_edge_pixels, short_edge_pixels),
            reference_position=(x, y, w, h),
            confidence=confidence,
            long_edge_mm=self.reference_obj.size_mm[0],
            short_edge_mm=self.reference_obj.size_mm[1]
        )

# ===== ç‰©ç†ç‰¹å¾å½’ä¸€åŒ–å¤„ç†å™¨ =====
class PhysicalFeatureNormalizer:
    """ç‰©ç†ç‰¹å¾å½’ä¸€åŒ–å¤„ç†å™¨"""
    
    def __init__(self, pixel_per_mm: float, calibration_confidence: float = 1.0):
        self.pixel_per_mm = pixel_per_mm
        self.calibration_confidence = calibration_confidence
        
    def normalize_geometric_features(self, features: dict) -> dict:
        """å½’ä¸€åŒ–å‡ ä½•ç‰¹å¾"""
        normalized = features.copy()
        
        # é¢ç§¯å½’ä¸€åŒ–: pixelÂ² -> mmÂ²
        if 'area' in features:
            normalized['area_mm2'] = features['area'] / (self.pixel_per_mm ** 2)
        
        # å‘¨é•¿å½’ä¸€åŒ–: pixel -> mm
        if 'perimeter' in features:
            normalized['perimeter_mm'] = features['perimeter'] / self.pixel_per_mm
        
        # è¾¹ç•Œæ¡†å½’ä¸€åŒ–
        if 'bounding_rect' in features:
            x, y, w, h = features['bounding_rect']
            normalized['bounding_rect_mm'] = (
                x / self.pixel_per_mm,
                y / self.pixel_per_mm,
                w / self.pixel_per_mm,
                h / self.pixel_per_mm
            )
        
        # ä¿ç•™åŸå§‹åƒç´ ç‰¹å¾ç”¨äºè°ƒè¯•
        normalized['_original_pixel_features'] = {
            'area_px': features.get('area', 0),
            'perimeter_px': features.get('perimeter', 0)
        }
        
        # æ·»åŠ å½’ä¸€åŒ–å…ƒæ•°æ®
        normalized['_normalization_info'] = {
            'pixel_per_mm': self.pixel_per_mm,
            'confidence': self.calibration_confidence,
            'normalized': True,
            'timestamp': datetime.now().isoformat()
        }
        
        return normalized
    
    def normalize_contour_points(self, contour: np.ndarray) -> np.ndarray:
        """å½’ä¸€åŒ–è½®å»“ç‚¹åæ ‡åˆ°ç‰©ç†å°ºåº¦"""
        normalized_contour = contour.astype(float)
        normalized_contour[:, :, 0] /= self.pixel_per_mm  # xåæ ‡
        normalized_contour[:, :, 1] /= self.pixel_per_mm  # yåæ ‡
        return normalized_contour
    
    def normalize_fourier_descriptors(self, descriptors: np.ndarray, fourier_order: int = 80) -> np.ndarray:
        """å½’ä¸€åŒ–å‚…é‡Œå¶æè¿°ç¬¦"""
        if len(descriptors) == 0:
            return descriptors
        
        normalized_descriptors = descriptors.copy()
        
        # DCåˆ†é‡ï¼ˆ0é˜¶ï¼‰éœ€è¦å°ºåº¦å½’ä¸€åŒ–
        if len(normalized_descriptors) > 0:
            normalized_descriptors[0] /= self.pixel_per_mm
        
        # å¦‚æœæœ‰Yåæ ‡çš„DCåˆ†é‡ä¹Ÿéœ€è¦å½’ä¸€åŒ–
        if len(normalized_descriptors) > fourier_order:
            normalized_descriptors[fourier_order] /= self.pixel_per_mm
        
        return normalized_descriptors

# ===== å°ºåº¦æ ‡å®šç›¸å…³ç±»å®šä¹‰ç»“æŸ =====

class FourierAnalyzer:
    @staticmethod
    def fit_fourier_series(data: np.ndarray, t: np.ndarray, order: int) -> np.ndarray:
        try:
            A = np.ones((len(t), 2 * order + 1))
            for k in range(1, order + 1):
                A[:, 2 * k - 1] = np.cos(k * t)
                A[:, 2 * k] = np.sin(k * t)
            coeffs, _, _, _ = lstsq(A, data, rcond=None)
            return coeffs
        except Exception as e:
            logger.error(f"å‚…é‡Œå¶çº§æ•°æ‹Ÿåˆå¤±è´¥: {e}")
            return np.zeros(2 * order + 1)

    @staticmethod
    def evaluate_fourier_series(coeffs: np.ndarray, t: np.ndarray, order: int) -> np.ndarray:
        A = np.ones((len(t), 2 * order + 1))
        for k in range(1, order + 1):
            A[:, 2 * k - 1] = np.cos(k * t)
            A[:, 2 * k] = np.sin(k * t)
        return A @ coeffs

    def analyze_contour(self, points: np.ndarray, order: int = 80, center_normalize: bool = True) -> dict:
        try:
            x = points[:, 0].astype(float)
            y = points[:, 1].astype(float)
            center_x = np.mean(x)
            center_y = np.mean(y)
            if center_normalize:
                x_normalized = x - center_x
                y_normalized = y - center_y
                max_dist = np.max(np.sqrt(x_normalized**2 + y_normalized**2))
                if max_dist > 0:
                    x_normalized /= max_dist
                    y_normalized /= max_dist
            else:
                x_normalized = x
                y_normalized = y
                max_dist = 1.0
            N = len(points)
            t = np.linspace(0, 2 * np.pi, N)
            coeffs_x = self.fit_fourier_series(x_normalized, t, order)
            coeffs_y = self.fit_fourier_series(y_normalized, t, order)
            t_dense = np.linspace(0, 2 * np.pi, N * 4)
            x_fit_normalized = self.evaluate_fourier_series(coeffs_x, t_dense, order)
            y_fit_normalized = self.evaluate_fourier_series(coeffs_y, t_dense, order)
            if center_normalize:
                x_fit = x_fit_normalized * max_dist + center_x
                y_fit = y_fit_normalized * max_dist + center_y
            else:
                x_fit = x_fit_normalized
                y_fit = y_fit_normalized
            return {
                'coeffs_x': coeffs_x,
                'coeffs_y': coeffs_y,
                'center_x': center_x,
                'center_y': center_y,
                'max_dist': max_dist,
                'order': order,
                'x_fit': x_fit,
                'y_fit': y_fit,
                'original_points': (x, y)
            }
        except Exception as e:
            logger.error(f"å‚…é‡Œå¶åˆ†æå¤±è´¥: {e}")
            return {}  # ä¿®æ­£ï¼šå§‹ç»ˆè¿”å›dict

class ContourFeatureExtractor:
    def __init__(self):
        self.fourier_analyzer = FourierAnalyzer()

    def extract_geometric_features(self, contour: np.ndarray, image_shape=None) -> dict:
        features = {}
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)
        if image_shape is not None:
            h, w = image_shape[:2]
            diag = (h**2 + w**2) ** 0.5
            area_norm = area / (diag ** 2)
            perimeter_norm = perimeter / diag
        else:
            area_norm = area
            perimeter_norm = perimeter
        x, y, w_box, h_box = cv2.boundingRect(contour)
        aspect_ratio = w_box / h_box if h_box != 0 else 0
        circularity = (4 * np.pi * area) / (perimeter * perimeter) if perimeter != 0 else 0
        hull = cv2.convexHull(contour)
        hull_area = cv2.contourArea(hull)
        solidity = area / hull_area if hull_area != 0 else 0
        epsilon = 0.02 * perimeter
        approx = cv2.approxPolyDP(contour, epsilon, True)
        corner_count = len(approx)
        features.update({
            'area': area,
            'perimeter': perimeter,
            'area_norm': area_norm,
            'perimeter_norm': perimeter_norm,
            'aspect_ratio': aspect_ratio,
            'circularity': circularity,
            'solidity': solidity,
            'corner_count': corner_count,
            'bounding_rect': (x, y, w_box, h_box)
        })
        return features

    def extract_hu_moments(self, contour: np.ndarray) -> np.ndarray:
        try:
            moments = cv2.moments(contour)
            hu_moments = cv2.HuMoments(moments).flatten()
            for i in range(len(hu_moments)):
                if hu_moments[i] != 0:
                    hu_moments[i] = -1 * np.copysign(1.0, hu_moments[i]) * np.log10(abs(hu_moments[i]))
                else:
                    hu_moments[i] = 0
            return hu_moments
        except Exception as e:
            logger.error(f"HuçŸ©è®¡ç®—å¤±è´¥: {e}")
            return np.zeros(7)

    def extract_fourier_descriptors(self, points: np.ndarray) -> np.ndarray:
        try:
            fourier_data = self.fourier_analyzer.analyze_contour(points, center_normalize=True)
            if fourier_data is not None:
                coeffs_x = fourier_data['coeffs_x']
                coeffs_y = fourier_data['coeffs_y']
                fourier_features = np.concatenate([coeffs_x[:11], coeffs_y[:11]])
                return fourier_features
            else:
                return np.zeros(22)
        except Exception as e:
            logger.error(f"å‚…é‡Œå¶æè¿°ç¬¦æå–å¤±è´¥: {e}")
            return np.zeros(22)

    def extract_all_features(self, contour: np.ndarray, points: np.ndarray, image_shape=None) -> dict:
        features = {}
        geometric_features = self.extract_geometric_features(contour, image_shape=image_shape)
        features.update(geometric_features)
        features['hu_moments'] = self.extract_hu_moments(contour)
        features['fourier_descriptors'] = self.extract_fourier_descriptors(points)
        fourier_data = self.fourier_analyzer.analyze_contour(points, center_normalize=True)
        if fourier_data is not None:
            features['fourier_x_fit'] = fourier_data['x_fit'].tolist()
            features['fourier_y_fit'] = fourier_data['y_fit'].tolist()
        return features

matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # é»‘ä½“
matplotlib.rcParams['axes.unicode_minus'] = False

class ToothTemplateBuilder:
    def __init__(self, database_path="tooth_templates.db", templates_dir="templates"):
        self.database_path = database_path
        self.templates_dir = Path(templates_dir)
        self.templates_dir.mkdir(exist_ok=True)
        (self.templates_dir / "contours").mkdir(exist_ok=True)
        (self.templates_dir / "images").mkdir(exist_ok=True)
        (self.templates_dir / "features").mkdir(exist_ok=True)  # ç¡®ä¿featuresç›®å½•å­˜åœ¨
        
        # åŸæœ‰ç»„ä»¶
        self.feature_extractor = ContourFeatureExtractor()
        self.current_image = None
        
        # æ–°å¢ï¼šæ ‡å®šç›¸å…³ç»„ä»¶
        self.reference_detector = ReferenceDetector(
            ReferenceObject(size_mm=(134.0, 9.0))  # 134mmÃ—9mmé•¿æ–¹å½¢æ ‡å®šç‰©
        )
        self.feature_normalizer = None  # åŠ¨æ€åˆå§‹åŒ–ï¼ŒåŸºäºæ ‡å®šç»“æœ
        self.calibration_mode = "auto"  # auto, manual, traditional
        
        # è´¨é‡æ§åˆ¶å‚æ•°
        self.min_calibration_confidence = 0.8
        self.require_calibration = True
        self.enable_normalization = True
        
        # åˆå§‹åŒ–æ•°æ®åº“ï¼ˆåŒ…å«æ–°çš„æ ‡å®šè¡¨ï¼‰
        self.init_database()
        
        logger.info(f"ğŸ—ï¸ ToothTemplateBuilderåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ ‡å®šæ¨¡å¼: {self.calibration_mode}")
        logger.info(f"   æ ‡å®šç‰©è§„æ ¼: 134mmÃ—9mm é•¿æ–¹å½¢")
        logger.info(f"   æœ€å°ç½®ä¿¡åº¦: {self.min_calibration_confidence}")
        logger.info(f"   ç‰¹å¾å½’ä¸€åŒ–: {'å¯ç”¨' if self.enable_normalization else 'ç¦ç”¨'}")
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“ï¼ŒåŒ…å«æ ‡å®šå’Œå½’ä¸€åŒ–ç›¸å…³è¡¨"""
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        
        # åŸæœ‰çš„æ¨¡æ¿è¡¨ï¼ˆæ‰©å±•å­—æ®µï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS templates (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tooth_id TEXT UNIQUE NOT NULL,
                name TEXT,
                image_path TEXT,
                contour_file TEXT,
                num_contours INTEGER,
                total_area REAL,
                
                -- æ–°å¢ï¼šæ ‡å®šç›¸å…³å­—æ®µ
                pixel_per_mm REAL,
                calibration_confidence REAL,
                reference_position TEXT,
                physical_area_mm2 REAL,
                physical_perimeter_mm REAL,
                is_normalized BOOLEAN DEFAULT 0,
                
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # æ–°å¢ï¼šæ ‡å®šè®°å½•è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS calibration_records (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tooth_id TEXT,
                pixel_per_mm REAL,
                confidence REAL,
                reference_type TEXT DEFAULT 'rectangle_134x9',
                reference_position TEXT,
                long_edge_pixels REAL,
                short_edge_pixels REAL,
                calibration_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                calibration_method TEXT DEFAULT 'auto'
            )
        ''')
        
        # æ–°å¢ï¼šç‰©ç†ç‰¹å¾è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS physical_features (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tooth_id TEXT,
                contour_idx INTEGER,
                area_mm2 REAL,
                perimeter_mm REAL,
                bbox_width_mm REAL,
                bbox_height_mm REAL,
                centroid_x_mm REAL,
                centroid_y_mm REAL,
                is_normalized BOOLEAN DEFAULT 1
            )
        ''')
        
        # æ–°å¢ï¼šå½’ä¸€åŒ–å…ƒæ•°æ®è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS normalization_metadata (
                tooth_id TEXT PRIMARY KEY,
                normalization_version TEXT DEFAULT 'v2.0_physical',
                source_image_resolution TEXT,
                pixel_density_dpi REAL,
                processing_pipeline_version TEXT DEFAULT '1.0',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ–°åˆ—åˆ°ç°æœ‰è¡¨ï¼ˆå‘åå…¼å®¹ï¼‰
        try:
            cursor.execute("ALTER TABLE templates ADD COLUMN pixel_per_mm REAL")
            cursor.execute("ALTER TABLE templates ADD COLUMN calibration_confidence REAL")
            cursor.execute("ALTER TABLE templates ADD COLUMN reference_position TEXT")
            cursor.execute("ALTER TABLE templates ADD COLUMN physical_area_mm2 REAL")
            cursor.execute("ALTER TABLE templates ADD COLUMN physical_perimeter_mm REAL")
            cursor.execute("ALTER TABLE templates ADD COLUMN is_normalized BOOLEAN DEFAULT 0")
            logger.info("ğŸ“Š æ•°æ®åº“ç»“æ„å·²å‡çº§ï¼Œæ”¯æŒæ ‡å®šåŠŸèƒ½")
        except sqlite3.OperationalError:
            # åˆ—å·²å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯
            pass
        
        conn.commit()
        conn.close()
        logger.info(f"âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.database_path}")
        logger.info("ğŸ“‹ æ•°æ®åº“è¡¨ç»“æ„:")
        logger.info("   â€¢ templates: æ¨¡æ¿åŸºæœ¬ä¿¡æ¯ (å·²æ‰©å±•)")
        logger.info("   â€¢ calibration_records: æ ‡å®šè®°å½•")
        logger.info("   â€¢ physical_features: ç‰©ç†ç‰¹å¾æ•°æ®")
        logger.info("   â€¢ normalization_metadata: å½’ä¸€åŒ–å…ƒæ•°æ®")

    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        return sqlite3.connect(self.database_path)

    def get_next_tooth_id(self):
        """ç”Ÿæˆä¸‹ä¸€ä¸ªè¿ç»­çš„ç‰™æ¨¡ç¼–å·"""
        contours_dir = self.templates_dir / "contours"
        if not contours_dir.exists():
            return "TOOTH_001"
        
        existing_files = list(contours_dir.glob("TOOTH_*.json"))
        if not existing_files:
            return "TOOTH_001"
        
        # æå–ç¼–å·å¹¶æ‰¾åˆ°æœ€å¤§å€¼
        max_num = 0
        for file in existing_files:
            try:
                num_str = file.stem.split('_')[1]  # TOOTH_001 -> 001
                num = int(num_str)
                max_num = max(max_num, num)
            except (IndexError, ValueError):
                continue
        
        return f"TOOTH_{max_num + 1:03d}"

    def serialize_contours(self, valid_contours, tooth_id=None, image_path=None, hsv_info=None, auto_save=False):
        """åºåˆ—åŒ–è½®å»“æ•°æ® - é‡æ„ç‰ˆæœ¬ï¼Œé›†æˆæ ‡å®šå’Œå½’ä¸€åŒ–åŠŸèƒ½
        
        æ–°çš„å·¥ä½œæµç¨‹ï¼š
        1. è½½å…¥åŸå§‹å›¾åƒ
        2. è‡ªåŠ¨æ£€æµ‹é•¿æ–¹å½¢æ ‡å®šç‰© (134mmÃ—9mm)
        3. è®¡ç®—pixel_per_mmæ¯”ä¾‹å’Œç½®ä¿¡åº¦
        4. è¿›è¡Œé¢œè‰²é€‰æ‹©å’Œè½®å»“æå–  
        5. å¯¹æ‰€æœ‰ç‰¹å¾è¿›è¡Œç‰©ç†å½’ä¸€åŒ–
        6. ä¿å­˜å½’ä¸€åŒ–åçš„æ¨¡æ¿æ•°æ®
        """
        try:
            if tooth_id is None:
                tooth_id = self.get_next_tooth_id()
            
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æ¨¡æ¿ {tooth_id}ï¼Œ{len(valid_contours)} ä¸ªè½®å»“")
            
            # ===== ç¬¬1æ­¥ï¼šæ ‡å®šç‰©æ£€æµ‹ =====
            calibration_result = None
            if self.enable_normalization and image_path:
                logger.info("ğŸ” å¼€å§‹é•¿æ–¹å½¢æ ‡å®šç‰©æ£€æµ‹...")
                try:
                    image = cv2.imread(str(image_path)) if isinstance(image_path, (str, Path)) else self.current_image
                    if image is not None:
                        calibration_result = self.reference_detector.detect_reference_object(image)
                        
                        if calibration_result.pixel_per_mm > 0:
                            logger.info(f"âœ… æ ‡å®šæˆåŠŸ! ç½®ä¿¡åº¦: {calibration_result.confidence:.3f}")
                            
                            # æ£€æŸ¥ç½®ä¿¡åº¦æ˜¯å¦æ»¡è¶³è¦æ±‚
                            if calibration_result.confidence < self.min_calibration_confidence:
                                logger.warning(f"âš ï¸ æ ‡å®šç½®ä¿¡åº¦ {calibration_result.confidence:.3f} ä½äºé˜ˆå€¼ {self.min_calibration_confidence}")
                                if self.require_calibration:
                                    logger.error("âŒ ç”±äºç½®ä¿¡åº¦ä¸è¶³ï¼Œç»ˆæ­¢å¤„ç†")
                                    return False
                                else:
                                    logger.info("ğŸ”„ ç»§ç»­å¤„ç†ä½†ä¸å¯ç”¨å½’ä¸€åŒ–")
                                    calibration_result = None
                        else:
                            logger.warning(f"âŒ æ ‡å®šå¤±è´¥: {calibration_result.error_message}")
                            if self.require_calibration:
                                logger.error("âŒ ç”±äºæ ‡å®šå¤±è´¥ï¼Œç»ˆæ­¢å¤„ç†")
                                return False
                            else:
                                logger.info("ğŸ”„ é™çº§åˆ°ä¼ ç»Ÿæ¨¡å¼")
                                calibration_result = None
                    else:
                        logger.warning("âš ï¸ æ— æ³•è½½å…¥å›¾åƒï¼Œè·³è¿‡æ ‡å®š")
                        calibration_result = None
                except Exception as e:
                    logger.error(f"âŒ æ ‡å®šè¿‡ç¨‹å¼‚å¸¸: {e}")
                    if self.require_calibration:
                        return False
                    calibration_result = None
            
            # ===== ç¬¬2æ­¥ï¼šåˆå§‹åŒ–ç‰¹å¾å½’ä¸€åŒ–å™¨ =====
            if calibration_result and calibration_result.pixel_per_mm > 0:
                self.feature_normalizer = PhysicalFeatureNormalizer(
                    calibration_result.pixel_per_mm,
                    calibration_result.confidence
                )
                normalization_enabled = True
                logger.info(f"ğŸ“ ç‰¹å¾å½’ä¸€åŒ–å™¨å·²åˆå§‹åŒ– (æ¯”ä¾‹: {calibration_result.pixel_per_mm:.4f} px/mm)")
            else:
                self.feature_normalizer = None
                normalization_enabled = False
                logger.info("ğŸ“ ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼ï¼ˆæ— å½’ä¸€åŒ–ï¼‰")
            
            # ===== ç¬¬3æ­¥ï¼šæ„å»ºæ¨¡æ¿æ•°æ®ç»“æ„ =====
            template_data = {
                "tooth_id": tooth_id,
                "image_path": str(image_path) if image_path else None,
                "created_at": datetime.now().isoformat(),
                "hsv_info": hsv_info,
                "num_contours": len(valid_contours),
                "contours": [],
                
                # æ–°å¢ï¼šæ ‡å®šä¿¡æ¯
                "calibration_info": {
                    "enabled": normalization_enabled,
                    "pixel_per_mm": calibration_result.pixel_per_mm if calibration_result else None,
                    "confidence": calibration_result.confidence if calibration_result else None,
                    "reference_position": calibration_result.reference_position if calibration_result else None,
                    "reference_type": "rectangle_134x9",
                    "method": self.calibration_mode
                } if calibration_result else {
                    "enabled": False,
                    "method": "traditional"
                },
                
                # ç‰ˆæœ¬ä¿¡æ¯
                "template_version": "v2.0_normalized" if normalization_enabled else "v1.0_pixel",
                "processing_pipeline": "1.0"
            }
            
            # ===== ç¬¬4æ­¥ï¼šå¤„ç†æ¯ä¸ªè½®å»“ =====
            total_area_pixels = 0
            total_area_mm2 = 0
            physical_features_data = []  # ç”¨äºä¿å­˜åˆ°ç‰©ç†ç‰¹å¾è¡¨
            
            for i, contour_info in enumerate(valid_contours):
                points = contour_info['points']
                contour = contour_info['contour']
                x, y, w, h = cv2.boundingRect(contour)
                
                # æå–åŸå§‹ç‰¹å¾
                original_features = self.feature_extractor.extract_all_features(
                    contour, points, 
                    image_shape=self.current_image.shape if hasattr(self, 'current_image') and self.current_image is not None else None
                )
                
                # ç‰©ç†å½’ä¸€åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if self.feature_normalizer:
                    normalized_features = self.feature_normalizer.normalize_geometric_features(original_features)
                    # å½’ä¸€åŒ–å‚…é‡Œå¶æè¿°ç¬¦
                    if 'fourier_descriptors' in original_features:
                        normalized_features['fourier_descriptors'] = self.feature_normalizer.normalize_fourier_descriptors(
                            original_features['fourier_descriptors']
                        ).tolist()
                    
                    # ç‰©ç†å°ºå¯¸ç»Ÿè®¡
                    total_area_mm2 += normalized_features.get('area_mm2', 0)
                    
                    # ä¿å­˜ç‰©ç†ç‰¹å¾æ•°æ®
                    physical_features_data.append({
                        'contour_idx': i,
                        'area_mm2': normalized_features.get('area_mm2', 0),
                        'perimeter_mm': normalized_features.get('perimeter_mm', 0),
                        'bbox_width_mm': normalized_features.get('bounding_rect_mm', (0,0,0,0))[2],
                        'bbox_height_mm': normalized_features.get('bounding_rect_mm', (0,0,0,0))[3],
                        'centroid_x_mm': normalized_features.get('bounding_rect_mm', (0,0,0,0))[0],
                        'centroid_y_mm': normalized_features.get('bounding_rect_mm', (0,0,0,0))[1]
                    })
                else:
                    normalized_features = original_features
                
                # æ„å»ºè½®å»“æ•°æ®
                contour_data = {
                    "idx": i,
                    "original_idx": contour_info['idx'],
                    "points": points.tolist(),
                    "area": float(contour_info['area']),
                    "perimeter": float(contour_info['length']),
                    "bounding_box": {"x": int(x), "y": int(y), "width": int(w), "height": int(h)},
                    
                    # ç‰¹å¾æ•°æ®ï¼ˆåŸå§‹+å½’ä¸€åŒ–ï¼‰
                    "features": {
                        # åŸå§‹åƒç´ ç‰¹å¾
                        "pixel_features": {
                            "area": float(original_features['area']),
                            "perimeter": float(original_features['perimeter']),
                            "aspect_ratio": float(original_features['aspect_ratio']),
                            "circularity": float(original_features['circularity']),
                            "solidity": float(original_features['solidity']),
                            "corner_count": int(original_features['corner_count']),
                            "hu_moments": original_features['hu_moments'].tolist(),
                            "fourier_descriptors": original_features['fourier_descriptors'].tolist()
                        },
                        
                        # ç‰©ç†ç‰¹å¾ï¼ˆå¦‚æœå·²å½’ä¸€åŒ–ï¼‰
                        "physical_features": {
                            "area_mm2": normalized_features.get('area_mm2', None),
                            "perimeter_mm": normalized_features.get('perimeter_mm', None),
                            "bbox_mm": list(normalized_features.get('bounding_rect_mm', (None, None, None, None))),
                        } if self.feature_normalizer else {},
                        
                        # å°ºåº¦æ— å…³ç‰¹å¾
                        "scale_invariant_features": {
                            "aspect_ratio": float(original_features['aspect_ratio']),
                            "circularity": float(original_features['circularity']),
                            "solidity": float(original_features['solidity']),
                            "hu_moments": original_features['hu_moments'].tolist()
                        },
                        
                        # å½’ä¸€åŒ–çš„å‚…é‡Œå¶æè¿°ç¬¦
                        "normalized_fourier_descriptors": normalized_features.get('fourier_descriptors', original_features['fourier_descriptors']).tolist() if isinstance(normalized_features.get('fourier_descriptors', original_features['fourier_descriptors']), np.ndarray) else normalized_features.get('fourier_descriptors', original_features['fourier_descriptors'])
                    }
                }
                
                template_data["contours"].append(contour_data)
                total_area_pixels += contour_info['area']
            
            template_data["total_area"] = float(total_area_pixels)
            template_data["total_area_mm2"] = float(total_area_mm2) if normalization_enabled else None
            
            # ===== ç¬¬5æ­¥ï¼šä¿å­˜æ¨¡æ¿æ•°æ® =====
            # ä¿å­˜JSONæ–‡ä»¶
            json_filename = f"{tooth_id}.json"
            json_path = self.templates_dir / "contours" / json_filename
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(template_data, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜ç‰¹å¾æ–‡ä»¶åˆ° features ç›®å½•
            save_features_only(template_data["contours"], tooth_id)
            
            # ä¿å­˜è½®å»“å›¾åƒï¼ˆPNGæ ¼å¼ï¼‰
            png_filename = f"{tooth_id}.png"
            png_path = self.templates_dir / "images" / png_filename
            png_path.parent.mkdir(exist_ok=True)
            
            if hasattr(self, 'current_image') and self.current_image is not None:
                contour_img = self.current_image.copy()
                for contour_info in valid_contours:
                    cv2.drawContours(contour_img, [contour_info['contour']], -1, (0, 255, 0), 2)
                
                # å¦‚æœæœ‰æ ‡å®šç»“æœï¼Œæ ‡æ³¨æ ‡å®šç‰©ä½ç½®
                if calibration_result and calibration_result.pixel_per_mm > 0:
                    x, y, w, h = calibration_result.reference_position
                    cv2.rectangle(contour_img, (x, y), (x+w, y+h), (0, 0, 255), 3)
                    cv2.putText(contour_img, f"Calibration: {calibration_result.pixel_per_mm:.2f}px/mm", 
                               (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                cv2.imwrite(str(png_path), contour_img)
            
            # ===== ç¬¬6æ­¥ï¼šä¿å­˜åˆ°æ•°æ®åº“ =====
            self._save_to_database_extended(template_data, json_filename, image_path, 
                                          calibration_result, physical_features_data)
            
            # ===== ç¬¬7æ­¥ï¼šè®°å½•å¤„ç†ç»“æœ =====
            save_type = "è‡ªåŠ¨ä¿å­˜" if auto_save else "æ‰‹åŠ¨ä¿å­˜"
            if normalization_enabled:
                logger.info(f"âœ… å½’ä¸€åŒ–æ¨¡æ¿å·²{save_type}: {tooth_id}")
                logger.info(f"   ğŸ“Š {len(valid_contours)}ä¸ªè½®å»“, æ€»é¢ç§¯: {total_area_mm2:.2f} mmÂ²")
                logger.info(f"   ğŸ“ æ ‡å®šç²¾åº¦: {calibration_result.pixel_per_mm:.4f} px/mm (ç½®ä¿¡åº¦: {calibration_result.confidence:.3f})")
            else:
                logger.info(f"âœ… ä¼ ç»Ÿæ¨¡æ¿å·²{save_type}: {tooth_id}")
                logger.info(f"   ğŸ“Š {len(valid_contours)}ä¸ªè½®å»“, æ€»é¢ç§¯: {total_area_pixels:.0f} pxÂ²")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡æ¿ä¿å­˜å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def _save_to_database_extended(self, template_data, json_filename, image_path, 
                                 calibration_result, physical_features_data):
        """æ‰©å±•çš„æ•°æ®åº“ä¿å­˜æ–¹æ³•ï¼Œæ”¯æŒæ ‡å®šå’Œç‰©ç†ç‰¹å¾æ•°æ®"""
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        
        try:
            # ä¿å­˜ä¸»æ¨¡æ¿è®°å½•ï¼ˆæ‰©å±•ç‰ˆï¼‰
            cursor.execute('''
                INSERT OR REPLACE INTO templates 
                (tooth_id, name, image_path, contour_file, num_contours, total_area,
                 pixel_per_mm, calibration_confidence, reference_position, 
                 physical_area_mm2, physical_perimeter_mm, is_normalized)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                template_data["tooth_id"],
                f"ç‰™é½¿æ¨¡å‹ {template_data['tooth_id']}",
                str(image_path) if image_path else None,
                json_filename,
                template_data["num_contours"],
                template_data["total_area"],
                calibration_result.pixel_per_mm if calibration_result else None,
                calibration_result.confidence if calibration_result else None,
                json.dumps(calibration_result.reference_position) if calibration_result else None,
                template_data.get("total_area_mm2", None),
                None,  # total_perimeter_mm éœ€è¦è®¡ç®—
                1 if calibration_result else 0
            ))
            
            # ä¿å­˜æ ‡å®šè®°å½•
            if calibration_result:
                cursor.execute('''
                    INSERT INTO calibration_records 
                    (tooth_id, pixel_per_mm, confidence, reference_type, reference_position,
                     long_edge_pixels, short_edge_pixels, calibration_method)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    template_data["tooth_id"],
                    calibration_result.pixel_per_mm,
                    calibration_result.confidence,
                    'rectangle_134x9',
                    json.dumps(calibration_result.reference_position),
                    calibration_result.reference_pixel_size[0],
                    calibration_result.reference_pixel_size[1],
                    self.calibration_mode
                ))
            
            # ä¿å­˜ç‰©ç†ç‰¹å¾æ•°æ®
            for feature_data in physical_features_data:
                cursor.execute('''
                    INSERT INTO physical_features 
                    (tooth_id, contour_idx, area_mm2, perimeter_mm, bbox_width_mm, 
                     bbox_height_mm, centroid_x_mm, centroid_y_mm)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    template_data["tooth_id"],
                    feature_data['contour_idx'],
                    feature_data['area_mm2'],
                    feature_data['perimeter_mm'],
                    feature_data['bbox_width_mm'],
                    feature_data['bbox_height_mm'],
                    feature_data['centroid_x_mm'],
                    feature_data['centroid_y_mm']
                ))
            
            # ä¿å­˜å½’ä¸€åŒ–å…ƒæ•°æ®
            cursor.execute('''
                INSERT OR REPLACE INTO normalization_metadata 
                (tooth_id, normalization_version, processing_pipeline_version)
                VALUES (?, ?, ?)
            ''', (
                template_data["tooth_id"],
                template_data.get("template_version", "v1.0_pixel"),
                template_data.get("processing_pipeline", "1.0")
            ))
            
            conn.commit()
            logger.info("âœ… æ‰©å±•æ•°æ®åº“è®°å½•å·²ä¿å­˜")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
            conn.rollback()
        finally:
            conn.close()
    
    def save_to_database(self, template_data, json_filename, image_path):
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO templates 
                (tooth_id, name, image_path, contour_file, num_contours, total_area)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                template_data["tooth_id"],
                f"ç‰™é½¿æ¨¡å‹ {template_data['tooth_id']}",
                image_path,
                json_filename,
                template_data["num_contours"],
                template_data["total_area"]
            ))
            conn.commit()
            print(f"âœ… æ•°æ®åº“è®°å½•å·²ä¿å­˜")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
        finally:
            conn.close()

    def list_templates(self):
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        cursor.execute('SELECT tooth_id, num_contours, total_area, created_at FROM templates ORDER BY created_at DESC')
        templates = cursor.fetchall()
        conn.close()
        
        if templates:
            print("\nğŸ“‹ å·²ä¿å­˜çš„ç‰™é½¿æ¨¡æ¿:")
            print("-" * 50)
            for tooth_id, num_contours, total_area, created_at in templates:
                print(f"ID: {tooth_id:<15} | è½®å»“: {num_contours:<3} | é¢ç§¯: {total_area:<8.1f}")
        else:
            print("ğŸ“­ æš‚æ— ä¿å­˜çš„æ¨¡æ¿")
        return templates

    def load_saved_contours(self, tooth_id):
        """åŠ è½½å·²ä¿å­˜çš„è½®å»“æ•°æ®ç”¨äºæ¯”å¯¹
        Args:
            tooth_id: ç‰™æ¨¡ID
        Returns:
            dict: åŒ…å«è½®å»“ä¿¡æ¯çš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        json_path = self.templates_dir / "contours" / f"{tooth_id}.json"
        if not json_path.exists():
            print(f"âŒ æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {tooth_id}")
            return None
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                template_data = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡æ¿: {tooth_id}")
            return template_data
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡æ¿å¤±è´¥: {e}")
            return None

    def compare_with_saved_template(self, current_contours, template_tooth_id):
        """ç®€å•çš„è½®å»“æ¯”å¯¹ç¤ºä¾‹
        Args:
            current_contours: å½“å‰æ£€æµ‹åˆ°çš„è½®å»“åˆ—è¡¨
            template_tooth_id: è¦æ¯”å¯¹çš„æ¨¡æ¿ID
        Returns:
            dict: æ¯”å¯¹ç»“æœ
        """
        template_data = self.load_saved_contours(template_tooth_id)
        if not template_data:
            return {"success": False, "error": "æ— æ³•åŠ è½½æ¨¡æ¿"}
        
        current_count = len(current_contours)
        template_count = template_data['num_contours']
        
        # ç®€å•çš„æ•°é‡å’Œé¢ç§¯æ¯”å¯¹
        current_total_area = sum(info['area'] for info in current_contours)
        template_total_area = template_data['total_area']
        
        area_similarity = min(current_total_area, template_total_area) / max(current_total_area, template_total_area)
        count_match = current_count == template_count
        
        result = {
            "success": True,
            "template_id": template_tooth_id,
            "current_count": current_count,
            "template_count": template_count,
            "count_match": count_match,
            "current_area": current_total_area,
            "template_area": template_total_area,
            "area_similarity": area_similarity,
            "is_similar": area_similarity > 0.8 and count_match
        }
        
        print(f"\nğŸ“Š è½®å»“æ¯”å¯¹ç»“æœ:")
        print(f"   æ¨¡æ¿ID: {template_tooth_id}")
        print(f"   è½®å»“æ•°é‡: {current_count} vs {template_count} ({'âœ… åŒ¹é…' if count_match else 'âŒ ä¸åŒ¹é…'})")
        print(f"   æ€»é¢ç§¯: {current_total_area:.1f} vs {template_total_area:.1f}")
        print(f"   é¢ç§¯ç›¸ä¼¼åº¦: {area_similarity:.3f}")
        print(f"   æ•´ä½“ç›¸ä¼¼: {'âœ… æ˜¯' if result['is_similar'] else 'âŒ å¦'}")
        
        return result

    def list_all_saved_templates(self):
        """åˆ—å‡ºæ‰€æœ‰å·²ä¿å­˜çš„æ¨¡æ¿ID"""
        contours_dir = self.templates_dir / "contours"
        if not contours_dir.exists():
            return []
        
        template_files = list(contours_dir.glob("TOOTH_*.json"))
        template_ids = [f.stem for f in template_files]
        
        if template_ids:
            print(f"\nğŸ“ æ‰¾åˆ° {len(template_ids)} ä¸ªå·²ä¿å­˜æ¨¡æ¿:")
            for tid in sorted(template_ids):
                print(f"   - {tid}")
        
        return sorted(template_ids)

class BatchToothProcessor:
    """æ‰¹é‡ç‰™é½¿å›¾åƒå¤„ç†å™¨ - åŸºäºç°æœ‰çš„ToothTemplateBuilder"""
    
    def __init__(self, input_dir: str = "images", templates_dir: str = "templates", 
                 database_path: str = "tooth_templates.db"):
        self.input_dir = Path(input_dir)
        self.templates_dir = Path(templates_dir)
        self.database_path = database_path
        self.builder = ToothTemplateBuilder(database_path, str(templates_dir))
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.supported_formats = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif'}
        
        # æ‰¹é‡å¤„ç†çŠ¶æ€
        self.processed_files: List[str] = []
        self.failed_files: List[Tuple[str, str]] = []  # (æ–‡ä»¶å, é”™è¯¯ä¿¡æ¯)
        self.skipped_files: List[str] = []
        
        # é¢œè‰²æ¨¡æ¿ç¼“å­˜
        self.color_template: Optional[Dict] = None
        
        print(f"ğŸš€ æ‰¹é‡å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ğŸ“ è¾“å…¥ç›®å½•: {self.input_dir}")
        print(f"   ğŸ“„ æ¨¡æ¿ç›®å½•: {self.templates_dir}")
        print(f"   ğŸ—„ï¸ æ•°æ®åº“: {self.database_path}")
    
    def scan_image_files(self) -> List[Path]:
        """æ‰«æè¾“å…¥ç›®å½•ä¸­çš„æ‰€æœ‰æ”¯æŒçš„å›¾åƒæ–‡ä»¶"""
        if not self.input_dir.exists():
            raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.input_dir}")
        
        image_files = []
        for ext in self.supported_formats:
            pattern = str(self.input_dir / f"*{ext}")
            image_files.extend(glob.glob(pattern))
            pattern = str(self.input_dir / f"*{ext.upper()}")
            image_files.extend(glob.glob(pattern))
        
        image_files = [Path(f) for f in image_files]
        image_files = sorted(set(image_files))  # å»é‡å¹¶æ’åº
        
        print(f"ğŸ“¸ å‘ç° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶:")
        for i, file in enumerate(image_files[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"   {i:2d}. {file.name}")
        if len(image_files) > 10:
            print(f"   ... è¿˜æœ‰ {len(image_files) - 10} ä¸ªæ–‡ä»¶")
        
        return image_files
    
    def is_already_processed(self, image_path: Path) -> bool:
        """æ£€æŸ¥å›¾åƒæ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡ï¼ˆé€šè¿‡æ•°æ®åº“æŸ¥è¯¢ï¼‰"""
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        try:
            cursor.execute('SELECT tooth_id FROM templates WHERE image_path = ?', (str(image_path),))
            result = cursor.fetchone()
            return result is not None
        except Exception:
            return False
        finally:
            conn.close()
    
    def get_color_template_from_first_image(self, first_image_path: Path) -> Optional[Dict]:
        """ä»ç¬¬ä¸€å¼ å›¾åƒè·å–é¢œè‰²æ¨¡æ¿ï¼ˆäº¤äº’å¼é€‰æ‹©ï¼‰"""
        print(f"\nğŸ¨ è¯·åœ¨ç¬¬ä¸€å¼ å›¾åƒä¸­é€‰æ‹©ç›®æ ‡é¢œè‰²:")
        print(f"ğŸ“¸ {first_image_path.name}")
        
        img = cv2.imread(str(first_image_path))
        if img is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {first_image_path}")
            return None
        
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        picked = []
        
        def on_mouse(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDOWN:
                color = hsv[y, x]
                print(f"é€‰ä¸­ç‚¹HSV: {color}")
                picked.append(color)
        
        cv2.imshow("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º, å¤šç‚¹é€‰æ‹©åæŒ‰ESC)", img)
        cv2.setMouseCallback("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º, å¤šç‚¹é€‰æ‹©åæŒ‰ESC)", on_mouse)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
        if not picked:
            print("âŒ æœªé€‰å–é¢œè‰²")
            return None
        
        # è®¡ç®—HSVå¹³å‡å€¼
        hsv_arr = np.array(picked)
        h_mean, s_mean, v_mean = np.mean(hsv_arr, axis=0).astype(int)
        
        # åˆ›å»ºé¢œè‰²æ¨¡æ¿
        color_template = {
            'h_mean': int(h_mean),
            's_mean': int(s_mean),
            'v_mean': int(v_mean),
            'lower': [0, 0, 0],  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
            'upper': [15, 60, 61],  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
            'picked_points': len(picked)
        }
        
        print(f"âœ… é¢œè‰²æ¨¡æ¿åˆ›å»ºæˆåŠŸ:")
        print(f"   HSVå‡å€¼: ({h_mean}, {s_mean}, {v_mean})")
        print(f"   é€‰å–ç‚¹æ•°: {len(picked)}")
        
        return color_template
    
    def process_single_image_with_template(self, image_path: Path, 
                                         color_template: Dict, 
                                         show_interactive: bool = False) -> bool:
        """ä½¿ç”¨é¢œè‰²æ¨¡æ¿è‡ªåŠ¨å¤„ç†å•å¼ å›¾åƒ"""
        try:
            print(f"ğŸ”„ å¤„ç†ä¸­: {image_path.name}")
            
            # è¯»å–å›¾åƒ
            img = cv2.imread(str(image_path))
            if img is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            
            # åº”ç”¨é¢œè‰²æ¨¡æ¿è¿›è¡ŒHSVæ©ç 
            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
            lower = np.array(color_template['lower'])
            upper = np.array(color_template['upper'])
            
            mask = cv2.inRange(hsv, lower, upper)
            
            # å½¢æ€å­¦æ“ä½œ
            kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)
            
            # æ™ºèƒ½åˆ†ç¦»
            mask_processed = choose_separation_method(mask)
            
            # è½®å»“æ£€æµ‹
            contours, _ = cv2.findContours(mask_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
            valid_contours = []
            
            for i, contour in enumerate(contours):
                if contour.shape[0] < 20:
                    continue
                area = cv2.contourArea(contour)
                length = cv2.arcLength(contour, True)
                valid_contours.append({
                    'contour': contour,
                    'points': contour[:, 0, :],
                    'area': area,
                    'length': length,
                    'idx': i
                })
            
            if not valid_contours:
                raise ValueError("æœªæ£€æµ‹åˆ°æœ‰æ•ˆè½®å»“")
            
            # ç”Ÿæˆç‰™é½¿ID
            tooth_id = self.builder.get_next_tooth_id()
            
            # åˆ›å»ºHSVä¿¡æ¯
            hsv_info = {
                'h_mean': color_template['h_mean'],
                's_mean': color_template['s_mean'],
                'v_mean': color_template['v_mean'],
                'lower': color_template['lower'],
                'upper': color_template['upper']
            }
            
            # è‡ªåŠ¨ä¿å­˜ï¼ˆä¸æ˜¾ç¤ºäº¤äº’ç•Œé¢ï¼‰
            success = self.builder.serialize_contours(
                valid_contours, tooth_id, str(image_path), hsv_info, auto_save=True
            )
            
            if success:
                print(f"âœ… {image_path.name} -> {tooth_id} ({len(valid_contours)}ä¸ªè½®å»“)")
                return True
            else:
                raise ValueError("ä¿å­˜å¤±è´¥")
                
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ {image_path.name}: {error_msg}")
            self.failed_files.append((str(image_path), error_msg))
            return False
    
    def process_batch(self, skip_processed: bool = True, 
                     interactive_first: bool = True,
                     show_progress: bool = True) -> Dict:
        """æ‰¹é‡å¤„ç†æ‰€æœ‰å›¾åƒ"""
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†...")
        print("=" * 60)
        
        # æ‰«æå›¾åƒæ–‡ä»¶
        image_files = self.scan_image_files()
        if not image_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„å›¾åƒæ–‡ä»¶")
            return self._generate_report()
        
        # è¿‡æ»¤å·²å¤„ç†çš„æ–‡ä»¶
        if skip_processed:
            unprocessed_files = []
            for img_file in image_files:
                if self.is_already_processed(img_file):
                    self.skipped_files.append(str(img_file))
                    print(f"â­ï¸  è·³è¿‡å·²å¤„ç†: {img_file.name}")
                else:
                    unprocessed_files.append(img_file)
            image_files = unprocessed_files
        
        if not image_files:
            print("âœ… æ‰€æœ‰å›¾åƒéƒ½å·²å¤„ç†å®Œæˆ")
            return self._generate_report()
        
        print(f"\nğŸ“Š å¾…å¤„ç†å›¾åƒ: {len(image_files)} ä¸ª")
        
        # è·å–é¢œè‰²æ¨¡æ¿
        if interactive_first and self.color_template is None:
            self.color_template = self.get_color_template_from_first_image(image_files[0])
            if self.color_template is None:
                print("âŒ æ— æ³•è·å–é¢œè‰²æ¨¡æ¿ï¼Œæ‰¹é‡å¤„ç†ç»ˆæ­¢")
                return self._generate_report()
        
        # å¤„ç†æ‰€æœ‰å›¾åƒ
        total_files = len(image_files)
        for i, img_file in enumerate(image_files, 1):
            if show_progress:
                print(f"\nğŸ“ˆ è¿›åº¦: {i}/{total_files} ({i/total_files*100:.1f}%)")
            
            success = self.process_single_image_with_template(
                img_file, self.color_template, show_interactive=False
            )
            
            if success:
                self.processed_files.append(str(img_file))
        
        return self._generate_report()
    
    def _generate_report(self) -> Dict:
        """ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š"""
        total_found = len(self.processed_files) + len(self.failed_files) + len(self.skipped_files)
        
        report = {
            'total_found': total_found,
            'processed': len(self.processed_files),
            'failed': len(self.failed_files),
            'skipped': len(self.skipped_files),
            'success_rate': len(self.processed_files) / max(1, total_found - len(self.skipped_files)) * 100,
            'processed_files': self.processed_files,
            'failed_files': self.failed_files,
            'skipped_files': self.skipped_files
        }
        
        # æ‰“å°æŠ¥å‘Š
        print(f"\n" + "=" * 60)
        print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"=" * 60)
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   ğŸ” å‘ç°æ–‡ä»¶: {report['total_found']} ä¸ª")
        print(f"   âœ… æˆåŠŸå¤„ç†: {report['processed']} ä¸ª")
        print(f"   âŒ å¤„ç†å¤±è´¥: {report['failed']} ä¸ª")
        print(f"   â­ï¸  è·³è¿‡æ–‡ä»¶: {report['skipped']} ä¸ª")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {report['success_rate']:.1f}%")
        
        if self.failed_files:
            print(f"\nâŒ å¤±è´¥æ–‡ä»¶è¯¦æƒ…:")
            for file_path, error in self.failed_files:
                print(f"   â€¢ {Path(file_path).name}: {error}")
        
        return report

def process_image_with_color_template(image_path: str, color_template: Dict, 
                                    tooth_id: Optional[str] = None) -> bool:
    """ä¿®æ”¹åçš„é¢œè‰²å¤„ç†å‡½æ•°ï¼Œæ”¯æŒé¢„è®¾é¢œè‰²æ¨¡æ¿"""
    builder = ToothTemplateBuilder()
    
    img = cv2.imread(image_path)
    if img is None:
        print(f"âŒ å›¾ç‰‡è¯»å–å¤±è´¥: {image_path}")
        return False
    
    # ä½¿ç”¨é¢„è®¾çš„é¢œè‰²æ¨¡æ¿
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower = np.array(color_template['lower'])
    upper = np.array(color_template['upper'])
    
    hsv_info = {
        'h_mean': color_template['h_mean'],
        's_mean': color_template['s_mean'], 
        'v_mean': color_template['v_mean'],
        'lower': color_template['lower'],
        'upper': color_template['upper']
    }
    
    mask = cv2.inRange(hsv, lower, upper)
    
    # å…¶ä½™å¤„ç†é€»è¾‘ä¸åŸå‡½æ•°ç›¸åŒ...
    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)
    
    mask_processed = choose_separation_method(mask)
    contours, _ = cv2.findContours(mask_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    
    valid_contours = []
    for i, contour in enumerate(contours):
        if contour.shape[0] < 20:
            continue
        area = cv2.contourArea(contour)
        length = cv2.arcLength(contour, True)
        valid_contours.append({
            'contour': contour,
            'points': contour[:, 0, :],
            'area': area,
            'length': length,
            'idx': i
        })
    
    if not valid_contours:
        print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè½®å»“")
        return False
    
    if tooth_id is None:
        tooth_id = builder.get_next_tooth_id()
    
    success = builder.serialize_contours(valid_contours, tooth_id, image_path, hsv_info, auto_save=True)
    if success:
        print(f"âœ… è‡ªåŠ¨å¤„ç†å®Œæˆ: {tooth_id} ({len(valid_contours)}ä¸ªè½®å»“)")
    
    return success

def pick_color_and_draw_edge(image_path, tooth_id=None):
    """ç‰™é½¿é¢œè‰²é€‰æ‹©å’Œè½®å»“æå– - é›†æˆæ ‡å®šåŠŸèƒ½çš„æ–°ç‰ˆæœ¬
    
    æ–°çš„å·¥ä½œæµç¨‹ï¼š
    1. è½½å…¥å›¾åƒ
    2. è‡ªåŠ¨æ£€æµ‹é•¿æ–¹å½¢æ ‡å®šç‰© (134mmÃ—9mm)
    3. è®¡ç®—pixel_per_mmæ¯”ä¾‹å’Œç½®ä¿¡åº¦
    4. è¿›è¡Œé¢œè‰²é€‰æ‹©å’Œè½®å»“æå–  
    5. åº”ç”¨ç‰©ç†å°ºåº¦å¤„ç†
    6. ä¿å­˜å½’ä¸€åŒ–åçš„æ¨¡æ¿æ•°æ®
    """
    # åˆå§‹åŒ–æ¨¡æ¿å»ºç«‹å™¨
    builder = ToothTemplateBuilder()
    
    img = cv2.imread(image_path)
    if img is None:
        print("âŒ å›¾ç‰‡è¯»å–å¤±è´¥")
        return
    
    # ä¿å­˜åŸå§‹å›¾åƒåˆ°builderä¸­
    builder.current_image = img
    
    logger.info(f"ğŸš€ å¼€å§‹å¤„ç†å›¾åƒ: {image_path}")
    logger.info(f"   å›¾åƒå°ºå¯¸: {img.shape[1]}Ã—{img.shape[0]}")
    
    # ===== ç¬¬1æ­¥ï¼šé•¿æ–¹å½¢æ ‡å®šç‰©æ£€æµ‹ =====
    logger.info("ğŸ” å¼€å§‹æ£€æµ‹134mmÃ—9mmé•¿æ–¹å½¢æ ‡å®šç‰©...")
    
    # æ˜¾ç¤ºåŸå§‹å›¾åƒä»¥ä¾›ç”¨æˆ·æ£€æŸ¥æ ‡å®šç‰©
    display_img = img.copy()
    cv2.imshow("å›¾åƒé¢„è§ˆ - è¯·ç¡®è®¤æ ‡å®šç‰©æ¸…æ™°å¯è§ (æŒ‰ä»»æ„é”®ç»§ç»­)", display_img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    # æ‰§è¡Œæ ‡å®šæ£€æµ‹
    calibration_result = builder.reference_detector.detect_reference_object(img)
    
    if calibration_result.pixel_per_mm > 0:
        logger.info(f"âœ… æ ‡å®šæˆåŠŸ!")
        logger.info(f"   åƒç´ æ¯”ä¾‹: {calibration_result.pixel_per_mm:.4f} px/mm")
        logger.info(f"   ç½®ä¿¡åº¦: {calibration_result.confidence:.3f}")
        logger.info(f"   é•¿è¾¹: {calibration_result.reference_pixel_size[0]:.0f} px (134mm)")
        logger.info(f"   çŸ­è¾¹: {calibration_result.reference_pixel_size[1]:.0f} px (9mm)")
        
        # æ˜¾ç¤ºæ ‡å®šç»“æœ
        calib_img = img.copy()
        x, y, w, h = calibration_result.reference_position
        cv2.rectangle(calib_img, (x, y), (x+w, y+h), (0, 0, 255), 3)
        cv2.putText(calib_img, f"Calibration: {calibration_result.pixel_per_mm:.2f}px/mm", 
                   (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        cv2.putText(calib_img, f"Confidence: {calibration_result.confidence:.3f}", 
                   (x, y+h+25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        
        cv2.imshow("æ ‡å®šç»“æœ - çº¢æ¡†æ ‡å‡ºæ ‡å®šç‰© (æŒ‰ä»»æ„é”®ç»§ç»­)", calib_img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
        # æ£€æŸ¥ç½®ä¿¡åº¦
        if calibration_result.confidence < builder.min_calibration_confidence:
            logger.warning(f"âš ï¸ æ ‡å®šç½®ä¿¡åº¦ {calibration_result.confidence:.3f} ä½äºé˜ˆå€¼ {builder.min_calibration_confidence}")
            response = input("æ˜¯å¦ç»§ç»­å¤„ç†ï¼Ÿ(y/n): ").lower().strip()
            if response != 'y':
                logger.info("âŒ ç”¨æˆ·å–æ¶ˆå¤„ç†")
                return
        
        # åˆå§‹åŒ–ç‰¹å¾å½’ä¸€åŒ–å™¨
        builder.feature_normalizer = PhysicalFeatureNormalizer(
            calibration_result.pixel_per_mm,
            calibration_result.confidence
        )
        normalization_enabled = True
        
    else:
        logger.warning(f"âŒ æ ‡å®šå¤±è´¥: {calibration_result.error_message}")
        response = input("æ˜¯å¦ç»§ç»­ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼ï¼Ÿ(y/n): ").lower().strip()
        if response != 'y':
            logger.info("âŒ ç”¨æˆ·å–æ¶ˆå¤„ç†")
            return
        
        logger.info("ğŸ”„ ç»§ç»­ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼ï¼ˆæ— å°ºåº¦å½’ä¸€åŒ–ï¼‰")
        builder.feature_normalizer = None
        normalization_enabled = False
    
    # ===== ç¬¬2æ­¥ï¼šé¢œè‰²é€‰æ‹© =====
    logger.info("ğŸ¨ å¼€å§‹é¢œè‰²é€‰æ‹©...")
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    picked = []
    
    def on_mouse(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            color = hsv[y, x]
            logger.info(f"é€‰ä¸­ç‚¹HSV: {color}")
            picked.append(color)
            # åœ¨å›¾åƒä¸Šæ ‡è®°é€‰ä¸­ç‚¹
            cv2.circle(display_img, (x, y), 5, (0, 255, 0), 2)
            cv2.putText(display_img, f"{len(picked)}", (x+10, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            cv2.imshow("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º)", display_img)
    
    # åˆ›å»ºæ˜¾ç¤ºå›¾åƒå‰¯æœ¬
    display_img = img.copy()
    
    # å¦‚æœæœ‰æ ‡å®šç»“æœï¼Œåœ¨æ˜¾ç¤ºå›¾åƒä¸Šæ ‡å‡ºæ ‡å®šç‰©
    if normalization_enabled:
        x, y, w, h = calibration_result.reference_position
        cv2.rectangle(display_img, (x, y), (x+w, y+h), (255, 0, 0), 2)
        cv2.putText(display_img, "Calibration Object", (x, y-5), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
    
    cv2.imshow("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º)", display_img)
    cv2.setMouseCallback("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º)", on_mouse)
    
    print("ğŸ¯ é¢œè‰²é€‰æ‹©è¯´æ˜:")
    print("  â€¢ ç‚¹å‡»å›¾åƒä¸­çš„ç›®æ ‡åŒºåŸŸæ¥é€‰æ‹©é¢œè‰²")
    print("  â€¢ å¯ä»¥é€‰æ‹©å¤šä¸ªé¢œè‰²ç‚¹")
    print("  â€¢ æŒ‰ESCé”®å®Œæˆé€‰æ‹©")
    if normalization_enabled:
        print("  â€¢ è“æ¡†æ ‡å‡ºäº†ç”¨äºå°ºåº¦æ ‡å®šçš„é•¿æ–¹å½¢æ ‡å®šç‰©")
    
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    if not picked:
        logger.warning("âŒ æœªé€‰å–é¢œè‰²")
        return
    
    # ===== ç¬¬3æ­¥ï¼šHSVå¤„ç†å’Œæ©ç ç”Ÿæˆ =====
    hsv_arr = np.array(picked)
    h, s, v = np.mean(hsv_arr, axis=0).astype(int)
    logger.info(f"ğŸ“Š é¢œè‰²ç»Ÿè®¡: HSVå¹³å‡å€¼ = ({h}, {s}, {v})")
    
    # è‡ªé€‚åº”HSVèŒƒå›´è®¾ç½®
    tolerance = {'h': 15, 's': 60, 'v': 60}
    lower = np.array([
        max(0, h - tolerance['h']), 
        max(0, s - tolerance['s']), 
        max(0, v - tolerance['v'])
    ])
    upper = np.array([
        min(179, h + tolerance['h']), 
        min(255, s + tolerance['s']), 
        min(255, v + tolerance['v'])
    ])
    
    logger.info(f"ğŸ¨ HSVèŒƒå›´: lower={lower}, upper={upper}")
    
    # ä¿å­˜HSVä¿¡æ¯ï¼ˆåŒ…å«æ ‡å®šä¿¡æ¯ï¼‰
    hsv_info = {
        'h_mean': int(h), 's_mean': int(s), 'v_mean': int(v),
        'lower': lower.tolist(), 'upper': upper.tolist(),
        'picked_points': len(picked),
        'calibration_enabled': normalization_enabled
    }
    
    if normalization_enabled:
        # æ·»åŠ æ ‡å®šä¿¡æ¯åˆ°HSVä¿¡æ¯ä¸­
        hsv_info['calibration_info'] = {
            'pixel_per_mm': calibration_result.pixel_per_mm,
            'confidence': calibration_result.confidence,
            'reference_position': calibration_result.reference_position
        }
    
    mask = cv2.inRange(hsv, lower, upper)
    
    # ===== ç¬¬4æ­¥ï¼šå½¢æ€å­¦å¤„ç†å’Œè½®å»“æå– =====
    logger.info("ğŸ”§ æ‰§è¡Œå½¢æ€å­¦æ“ä½œ...")
    
    # å…ˆè¿›è¡Œå¼€è¿ç®—å»é™¤å™ªå£°
    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)
    
    # æ™ºèƒ½é€‰æ‹©åˆ†ç¦»æ–¹æ³•
    mask_processed = choose_separation_method(mask)
    
    # æ˜¾ç¤ºåˆ†ç¦»æ•ˆæœå¯¹æ¯”
    show_separation_comparison(mask, mask_processed, image_path)
    
    color_extract = cv2.bitwise_and(img, img, mask=mask_processed)
    
    # ===== ç¬¬5æ­¥ï¼šè½®å»“æ£€æµ‹å’Œç‰¹å¾æå– =====
    logger.info("ğŸ” æ£€æµ‹è½®å»“...")
    contours, _ = cv2.findContours(mask_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    valid_contours = []
    
    for i, contour in enumerate(contours):
        if contour.shape[0] < 20:
            continue
        area = cv2.contourArea(contour)
        length = cv2.arcLength(contour, True)
        valid_contours.append({
            'contour': contour,
            'points': contour[:, 0, :],
            'area': area,
            'length': length,
            'idx': i
        })
    
    logger.info(f"âœ… æ£€æµ‹åˆ° {len(valid_contours)} ä¸ªæœ‰æ•ˆè½®å»“")
    if not valid_contours:
        logger.error("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè½®å»“")
        return
    
    # ===== ç¬¬6æ­¥ï¼šå‡†å¤‡æ˜¾ç¤ºå’Œä¿å­˜ =====
    n_contours = len(valid_contours)
    linewidth = max(0.5, 2 - 0.03 * n_contours)
    show_legend = n_contours <= 15
    
    # è‡ªåŠ¨ç”Ÿæˆç‰™é½¿IDï¼ˆè¿ç»­ç¼–å·ï¼‰
    if tooth_id is None:
        tooth_id = builder.get_next_tooth_id()
    
    # ç‰©ç†å°ºå¯¸ç»Ÿè®¡ï¼ˆå¦‚æœå¯ç”¨äº†å½’ä¸€åŒ–ï¼‰
    if normalization_enabled:
        total_area_mm2 = sum(contour['area'] for contour in valid_contours) / (calibration_result.pixel_per_mm ** 2)
        total_perimeter_mm = sum(contour['length'] for contour in valid_contours) / calibration_result.pixel_per_mm
        logger.info(f"ğŸ“ ç‰©ç†å°ºå¯¸é¢„è§ˆ:")
        logger.info(f"   æ€»é¢ç§¯: {total_area_mm2:.2f} mmÂ²")
        logger.info(f"   æ€»å‘¨é•¿: {total_perimeter_mm:.2f} mm")
    else:
        total_area_px = sum(contour['area'] for contour in valid_contours)
        total_perimeter_px = sum(contour['length'] for contour in valid_contours)
        logger.info(f"ğŸ“Š åƒç´ å°ºå¯¸:")
        logger.info(f"   æ€»é¢ç§¯: {total_area_px:.0f} pxÂ²")
        logger.info(f"   æ€»å‘¨é•¿: {total_perimeter_px:.0f} px")
    
    # ===== ç¬¬7æ­¥ï¼šäº¤äº’å¼æ˜¾ç¤º =====
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    ax_img, ax_calib = axes[0]
    ax_contour, ax_zoom = axes[1]
    
    # åŸå§‹å›¾åƒ
    ax_img.set_title("åŸå§‹å›¾åƒ", fontsize=14)
    ax_img.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax_img.axis('off')
    
    # æ ‡å®šç»“æœæ˜¾ç¤º
    if normalization_enabled:
        ax_calib.set_title("æ ‡å®šç»“æœ", fontsize=14)
        calib_display = img.copy()
        x, y, w, h = calibration_result.reference_position
        cv2.rectangle(calib_display, (x, y), (x+w, y+h), (0, 0, 255), 3)
        ax_calib.imshow(cv2.cvtColor(calib_display, cv2.COLOR_BGR2RGB))
        ax_calib.text(0.02, 0.98, f"æ¯”ä¾‹: {calibration_result.pixel_per_mm:.3f} px/mm\nç½®ä¿¡åº¦: {calibration_result.confidence:.3f}\né•¿è¾¹: {calibration_result.reference_pixel_size[0]:.0f}px â†’ 134mm\nçŸ­è¾¹: {calibration_result.reference_pixel_size[1]:.0f}px â†’ 9mm", 
                     transform=ax_calib.transAxes, fontsize=10, verticalalignment='top',
                     bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        ax_calib.axis('off')
    else:
        ax_calib.set_title("ä¼ ç»Ÿæ¨¡å¼", fontsize=14)
        ax_calib.text(0.5, 0.5, "æœªå¯ç”¨å°ºåº¦æ ‡å®š\nä½¿ç”¨åƒç´ å•ä½", 
                     transform=ax_calib.transAxes, fontsize=12, ha='center', va='center',
                     bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
        ax_calib.axis('off')
    
    # è½®å»“æ˜¾ç¤º
    ax_contour.set_title(f"è½®å»“æ£€æµ‹ç»“æœ - ç‰™é½¿ID: {tooth_id}", fontsize=14)
    ax_contour.axis('equal')
    ax_contour.invert_yaxis()
    ax_contour.grid(True)
    
    # æ”¾å¤§è§†å›¾
    ax_zoom.set_title("é€‰ä¸­è½®å»“æ”¾å¤§è§†å›¾", fontsize=14)
    ax_zoom.axis('equal')
    ax_zoom.invert_yaxis()
    ax_zoom.grid(True)
    
    selected_idx = [0]  # ç”¨åˆ—è¡¨åŒ…è£¹ä»¥ä¾¿é—­åŒ…ä¿®æ”¹
    saved = [False]  # ä¿å­˜çŠ¶æ€
    
    # ===== ç¬¬8æ­¥ï¼šè‡ªåŠ¨ä¿å­˜æ¨¡æ¿ =====
    logger.info(f"ï¿½ å¼€å§‹ä¿å­˜æ¨¡æ¿ {tooth_id}...")
    success = builder.serialize_contours(valid_contours, tooth_id, image_path, hsv_info, auto_save=True)
    if success:
        saved[0] = True
        if normalization_enabled:
            logger.info(f"âœ… å½’ä¸€åŒ–æ¨¡æ¿å·²ä¿å­˜: {tooth_id}")
            logger.info(f"   ğŸ”¬ åŒ…å«æ ‡å®šä¿¡æ¯å’Œç‰©ç†ç‰¹å¾")
        else:
            logger.info(f"âœ… ä¼ ç»Ÿæ¨¡æ¿å·²ä¿å­˜: {tooth_id}")
    else:
        print(f"âŒ è‡ªåŠ¨ä¿å­˜å¤±è´¥")
    
    def draw_all(highlight_idx=None):
        # ä¸­é—´å›¾ï¼šæ˜¾ç¤ºå…¨éƒ¨è½®å»“
        ax_contour.clear()
        ax_contour.set_title(f"å…¨éƒ¨è½®å»“æ˜¾ç¤º - ç‰™é½¿ID: {tooth_id}")
        ax_contour.axis('equal')
        ax_contour.invert_yaxis()
        ax_contour.grid(True)
        
        # åœ¨åŸå›¾ä¸Šå åŠ æ‰€æœ‰è½®å»“
        img_display = img.copy()
        
        # å‡†å¤‡é¢œè‰²åˆ—è¡¨
        colors_bgr = [(0, 0, 255), (0, 255, 0), (255, 0, 0), (0, 255, 255), (255, 0, 255), (255, 255, 0)]
        cmap = plt.get_cmap('tab10')
        colors_plt = cmap(np.linspace(0, 1, max(len(valid_contours), 10)))
        
        for j, info in enumerate(valid_contours):
            contour = info['contour']
            color_bgr = colors_bgr[j % len(colors_bgr)]
            
            if highlight_idx is not None and j == highlight_idx:
                # é«˜äº®æ˜¾ç¤ºé€‰ä¸­çš„è½®å»“
                cv2.drawContours(img_display, [contour], -1, (0, 0, 255), 3)
                # æ·»åŠ æ ‡è®°ç‚¹
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    cv2.circle(img_display, (cx, cy), 8, (0, 0, 255), -1)
                    cv2.putText(img_display, f'{j+1}', (cx-8, cy+5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            else:
                # æ™®é€šæ˜¾ç¤ºå…¶ä»–è½®å»“
                cv2.drawContours(img_display, [contour], -1, color_bgr, 2)
                # æ·»åŠ ç¼–å·
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    cv2.putText(img_display, f'{j+1}', (cx-5, cy+3), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        ax_contour.imshow(cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB))
        ax_contour.axis('off')
        
        # å³è¾¹å›¾ï¼šæ˜¾ç¤ºé€‰ä¸­è½®å»“çš„æ”¾å¤§è§†å›¾
        ax_zoom.clear()
        if highlight_idx is not None:
            info = valid_contours[highlight_idx]
            contour = info['contour']
            
            # è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            margin = max(20, max(w, h) * 0.1)  # è‡ªé€‚åº”è¾¹è·
            
            # ä»åŸå›¾ä¸­è£å‰ªåŒºåŸŸ
            x1 = max(0, int(x - margin))
            y1 = max(0, int(y - margin))
            x2 = min(img.shape[1], int(x + w + margin))
            y2 = min(img.shape[0], int(y + h + margin))
            
            cropped_img = img[y1:y2, x1:x2].copy()
            
            # è°ƒæ•´è½®å»“åæ ‡åˆ°è£å‰ªå›¾åƒçš„åæ ‡ç³»
            adjusted_contour = contour.copy()
            adjusted_contour[:, 0, 0] -= x1
            adjusted_contour[:, 0, 1] -= y1
            
            # åœ¨è£å‰ªå›¾åƒä¸Šç»˜åˆ¶è½®å»“
            cv2.drawContours(cropped_img, [adjusted_contour], -1, (0, 0, 255), 3)
            # åˆ›å»ºåŠé€æ˜å¡«å……æ•ˆæœ
            overlay = cropped_img.copy()
            cv2.fillPoly(overlay, [adjusted_contour], (0, 0, 255))
            cv2.addWeighted(overlay, 0.3, cropped_img, 0.7, 0, cropped_img)
            
            ax_zoom.imshow(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
            ax_zoom.set_title(f"é€‰ä¸­è½®å»“ {highlight_idx+1} - é¢ç§¯: {info['area']:.1f} | å‘¨é•¿: {info['length']:.1f}")
        else:
            # å¦‚æœæ²¡æœ‰é€‰ä¸­è½®å»“ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
            ax_zoom.text(0.5, 0.5, 'ç‚¹å‡»è½®å»“æŸ¥çœ‹æ”¾å¤§è§†å›¾\nâ†â†’ é”®åˆ‡æ¢è½®å»“\nq é”®é€€å‡º\n\nâœ… æ¨¡æ¿å·²è‡ªåŠ¨ä¿å­˜', 
                        ha='center', va='center', transform=ax_zoom.transAxes, 
                        fontsize=12, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
            ax_zoom.set_title("è½®å»“æ”¾å¤§è§†å›¾")
        
        ax_zoom.axis('off')
        
        # çŠ¶æ€ä¿¡æ¯æ˜¾ç¤º
        if highlight_idx is not None:
            info = valid_contours[highlight_idx]
            status = "âœ… å·²è‡ªåŠ¨ä¿å­˜" if saved[0] else "âŒ æœªä¿å­˜"
            status_text = f"çŠ¶æ€: {status} | å½“å‰: {highlight_idx+1}/{len(valid_contours)} | é¢ç§¯: {info['area']:.1f} | å‘¨é•¿: {info['length']:.1f}"
        else:
            status = "âœ… å·²è‡ªåŠ¨ä¿å­˜" if saved[0] else "âŒ æœªä¿å­˜"
            status_text = f"çŠ¶æ€: {status} | å…± {len(valid_contours)} ä¸ªè½®å»“ | æ“ä½œ: â†â†’åˆ‡æ¢ qé€€å‡º"
        
        fig.suptitle(status_text, fontsize=12, y=0.02)
        
        fig.canvas.draw_idle()
    
    def on_click(event):
        if event.inaxes != ax_contour:
            return
        
        # è·å–ç‚¹å‡»åæ ‡ï¼ˆéœ€è¦è½¬æ¢åˆ°å›¾åƒåæ ‡ç³»ï¼‰
        if event.xdata is None or event.ydata is None:
            return
            
        # ç”±äºax_contouræ˜¾ç¤ºçš„æ˜¯å›¾åƒï¼Œåæ ‡ç³»ä¸åŸå›¾ä¸€è‡´
        x, y = int(event.xdata), int(event.ydata)
        
        # æ£€æŸ¥ç‚¹å‡»æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…
        if x < 0 or x >= img.shape[1] or y < 0 or y >= img.shape[0]:
            return
        
        found = False
        for j, info in enumerate(valid_contours):
            # æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨è½®å»“å†…
            if cv2.pointPolygonTest(info['contour'], (x, y), False) >= 0:
                selected_idx[0] = j
                draw_all(highlight_idx=j)
                found = True
                print(f"âœ… é€‰ä¸­è½®å»“ {j+1}")
                break
        
        if not found:
            print("æœªé€‰ä¸­ä»»ä½•è½®å»“")
    
    def on_key(event):
        if event.key == 'right':
            selected_idx[0] = (selected_idx[0] + 1) % n_contours
            draw_all(highlight_idx=selected_idx[0])
        elif event.key == 'left':
            selected_idx[0] = (selected_idx[0] - 1) % n_contours
            draw_all(highlight_idx=selected_idx[0])
        elif event.key == 'q':
            plt.close()
    
    draw_all(highlight_idx=0 if valid_contours else None)
    fig.canvas.mpl_connect('button_press_event', on_click)
    fig.canvas.mpl_connect('key_press_event', on_key)
    plt.tight_layout()
    plt.subplots_adjust(top=0.93)  # ä¸ºçŠ¶æ€ä¿¡æ¯ç•™å‡ºç©ºé—´
    plt.show()
    
    # æ˜¾ç¤ºå·²ä¿å­˜çš„æ¨¡æ¿åˆ—è¡¨
    builder.list_templates()

def ultra_separate_connected_objects(mask):
    """
    è¶…å¼ºé»è¿åˆ†ç¦»ç®—æ³• - ä»…ä½¿ç”¨OpenCVï¼Œæ— éœ€é¢å¤–ä¾èµ–
    """
    print("ğŸš€ å¯åŠ¨è¶…å¼ºåˆ†ç¦»ç®—æ³•ï¼ˆOpenCVç‰ˆæœ¬ï¼‰...")
    
    # æ­¥éª¤1: æ¸…ç†å™ªå£°
    kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask_clean = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_small)
    
    # æ­¥éª¤2: å¤šç­–ç•¥åˆ†ç¦»å°è¯•
    best_result = mask_clean
    max_components = 1
    
    # ç­–ç•¥1: æ¿€è¿›è…èš€åˆ†ç¦»
    erosion_configs = [
        (1, 3), (2, 3), (3, 3), (4, 3),  # å°æ ¸å¤šæ¬¡è¿­ä»£
        (1, 5), (2, 5), (3, 5),          # ä¸­æ ¸
        (1, 7), (2, 7)                   # å¤§æ ¸
    ]
    
    for iterations, kernel_size in erosion_configs:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        eroded = cv2.erode(mask_clean, kernel, iterations=iterations)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåˆ†ç¦»
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(eroded, connectivity=8)
        
        if num_labels > max_components:
            max_components = num_labels
            print(f"ğŸ’ª æ‰¾åˆ°æ›´å¥½åˆ†ç¦»: {num_labels-1} ä¸ªåŒºåŸŸ (è…èš€{iterations}æ¬¡,æ ¸{kernel_size}x{kernel_size})")
            
            # æ¢å¤å„ä¸ªåŒºåŸŸ
            result_mask = np.zeros_like(mask_clean)
            
            for i in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯
                # è·å–å½“å‰åŒºåŸŸ
                component = (labels == i).astype(np.uint8) * 255
                
                # æ¸è¿›è†¨èƒ€æ¢å¤
                restore_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, 
                                                         (min(kernel_size, 5), min(kernel_size, 5)))
                restored = cv2.dilate(component, restore_kernel, iterations=min(iterations, 2))
                
                # é™åˆ¶åœ¨åŸå§‹åŒºåŸŸå†…
                restored = cv2.bitwise_and(restored, mask_clean)
                
                result_mask = cv2.bitwise_or(result_mask, restored)
            
            best_result = result_mask
    
    print(f"âœ… è¶…å¼ºåˆ†ç¦»å®Œæˆï¼æœ€ç»ˆåˆ†ç¦»å‡º {max_components-1} ä¸ªç‹¬ç«‹åŒºåŸŸ")
    return best_result

def force_separation_with_morphology(mask):
    """
    å¼ºåˆ¶å½¢æ€å­¦åˆ†ç¦» - å½“åˆ†æ°´å²­å¤±è´¥æ—¶çš„ç»ˆæå¤‡é€‰æ–¹æ¡ˆ
    """
    print("ğŸ”§ å¯åŠ¨å¼ºåˆ¶å½¢æ€å­¦åˆ†ç¦»...")
    original_mask = mask.copy()
    best_result = mask.copy()
    max_components = 1
    
    # æåº¦æ¿€è¿›çš„è…èš€ç­–ç•¥
    erosion_configs = [
        (1, (3, 3)), (2, (3, 3)), (3, (3, 3)), (4, (3, 3)), (5, (3, 3)),
        (1, (5, 5)), (2, (5, 5)), (3, (5, 5)),
        (1, (7, 7)), (2, (7, 7)),
        (1, (9, 9))
    ]
    
    for iterations, kernel_size in erosion_configs:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)
        eroded = cv2.erode(original_mask, kernel, iterations=iterations)
        
        # æ£€æŸ¥è¿é€šåˆ†é‡
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(eroded, connectivity=8)
        
        if num_labels > max_components:
            max_components = num_labels
            result_mask = np.zeros_like(mask)
            
            for i in range(1, num_labels):
                component_mask = (labels == i).astype(np.uint8) * 255
                
                # æ¸è¿›å¼è†¨èƒ€æ¢å¤
                restore_iterations = min(iterations, 3)  # é™åˆ¶æ¢å¤å¼ºåº¦
                kernel_restore = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, 
                                                         (restore_iterations*2+1, restore_iterations*2+1))
                restored = cv2.dilate(component_mask, kernel_restore, iterations=restore_iterations)
                
                # é™åˆ¶åœ¨æ‰©å±•çš„åŸå§‹åŒºåŸŸå†…
                expanded_original = cv2.dilate(original_mask, np.ones((3,3), np.uint8), iterations=2)
                restored = cv2.bitwise_and(restored, expanded_original)
                
                result_mask = cv2.bitwise_or(result_mask, restored)
            
            best_result = result_mask.copy()
            print(f"ğŸ’ª å½¢æ€å­¦æ–¹æ¡ˆæ‰¾åˆ° {max_components-1} ä¸ªåŒºåŸŸ (è…èš€{iterations}æ¬¡,æ ¸{kernel_size})")
    
    print(f"âœ… å¼ºåˆ¶åˆ†ç¦»å®Œæˆï¼Œæœ€ç»ˆåˆ†ç¦»å‡º {max_components-1} ä¸ªåŒºåŸŸ")
    return best_result
    """
    è¶…å¼ºé»è¿åˆ†ç¦»ç®—æ³• - é’ˆå¯¹ç‰™é½¿æ¨¡å‹ä¼˜åŒ–
    """
    # æ­¥éª¤1: é¢„å¤„ç† - å»é™¤å°å™ªå£°å’Œå¹³æ»‘
    mask_bool = mask > 0
    mask_clean = remove_small_objects(mask_bool, min_size=30, connectivity=2)
    mask_clean = binary_opening(mask_clean, disk(1))  # å‡å°‘å¼€è¿ç®—å¼ºåº¦
    mask_clean = mask_clean.astype(np.uint8) * 255
    
    # æ­¥éª¤2: é«˜ç²¾åº¦è·ç¦»å˜æ¢
    dist_transform = distance_transform_edt(mask_clean)
    
    # æ­¥éª¤3: æ›´æ¿€è¿›çš„å‚æ•°è®¾ç½® - ä¸“é—¨é’ˆå¯¹ç‰™é½¿é»è¿
    img_area = mask_clean.shape[0] * mask_clean.shape[1]
    max_dist = np.max(dist_transform)
    
    # æ›´æ¿€è¿›çš„å‚æ•°ï¼Œå¼ºåˆ¶åˆ†ç¦»é»è¿ç‰™é½¿
    if img_area > 500000:  # å¤§å›¾åƒ
        min_distance = 2  # æå°
        threshold_abs = max_dist * 0.05  # æ›´ä½
        threshold_rel = 0.02
    elif img_area > 100000:  # ä¸­ç­‰å›¾åƒ
        min_distance = 1
        threshold_abs = max_dist * 0.03
        threshold_rel = 0.01
    else:  # å°å›¾åƒ
        min_distance = 1
        threshold_abs = max_dist * 0.01
        threshold_rel = 0.005
    
    print(f"ğŸ” è·ç¦»å˜æ¢æœ€å¤§å€¼: {max_dist:.2f}")
    print(f"ğŸ“Š å‚æ•°è®¾ç½® - æœ€å°è·ç¦»: {min_distance}, é˜ˆå€¼: {threshold_abs:.2f}")
    
    # æ­¥éª¤4: å¯»æ‰¾å±€éƒ¨æœ€å¤§å€¼ä½œä¸ºåˆ†ç¦»ç§å­
    local_maxima = peak_local_max(
        dist_transform,
        min_distance=min_distance,
        threshold_abs=threshold_abs,
        threshold_rel=threshold_rel,
        exclude_border=False
    )
    
    print(f"ğŸ¯ æ£€æµ‹åˆ° {len(local_maxima)} ä¸ªé«˜è´¨é‡åˆ†ç¦»ç§å­ç‚¹")
    
    if len(local_maxima) == 0:
        print("âš ï¸ æœªæ‰¾åˆ°åˆ†ç¦»ç‚¹ï¼Œé™ä½é˜ˆå€¼é‡è¯•...")
        # é™ä½é˜ˆå€¼é‡è¯•
        local_maxima = peak_local_max(
            dist_transform,
            min_distance=max(min_distance//2, 3),
            threshold_abs=threshold_abs * 0.5,
            threshold_rel=threshold_rel * 0.5
        )
        print(f"ğŸ”„ é‡è¯•åæ£€æµ‹åˆ° {len(local_maxima)} ä¸ªç§å­ç‚¹")
    
    if len(local_maxima) == 0:
        print("âŒ ä»æœªæ‰¾åˆ°åˆ†ç¦»ç‚¹ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ")
        return advanced_separate_connected_objects(mask_clean)
    
    # æ­¥éª¤5: åˆ›å»ºé«˜è´¨é‡æ ‡è®°å›¾åƒ
    markers = np.zeros_like(mask_clean, dtype=np.int32)
    for i, (y, x) in enumerate(local_maxima):
        markers[y, x] = i + 1
    
    # ä½¿ç”¨å½¢æ€å­¦è†¨èƒ€æ‰©å±•æ ‡è®°ï¼Œä½†æ§åˆ¶æ‰©å±•ç¨‹åº¦
    expansion_size = max(1, min_distance // 4)
    markers = ndimage.binary_dilation(
        markers > 0, 
        structure=disk(expansion_size)
    ).astype(np.int32)
    
    # é‡æ–°æ ‡è®°è¿é€šåˆ†é‡
    markers = label(markers)
    
    # æ­¥éª¤6: é«˜æ€§èƒ½åˆ†æ°´å²­åˆ†å‰²
    labels = watershed(-dist_transform, markers, mask=mask_clean)
    
    # æ­¥éª¤7: æ™ºèƒ½åå¤„ç†
    result_mask = np.zeros_like(mask_clean)
    regions = regionprops(labels)
    
    min_area = 100  # æœ€å°åŒºåŸŸé¢ç§¯
    processed_regions = 0
    
    for region in regions:
        if region.area < min_area:
            continue
            
        # è·å–åŒºåŸŸmask
        region_mask = (labels == region.label).astype(np.uint8) * 255
        
        # å½¢æ€å­¦é—­è¿ç®—å¡«è¡¥ç©ºæ´ï¼Œä½¿ç”¨è‡ªé€‚åº”æ ¸å¤§å°
        close_size = max(1, int(np.sqrt(region.area) * 0.05))
        kernel_close = disk(close_size)
        region_mask = ndimage.binary_closing(region_mask, structure=kernel_close)
        region_mask = region_mask.astype(np.uint8) * 255
        
        # åˆå¹¶åˆ°ç»“æœ
        result_mask = cv2.bitwise_or(result_mask, region_mask)
        processed_regions += 1
    
    print(f"âœ… é«˜æ€§èƒ½åˆ†ç¦»å®Œæˆï¼ç”Ÿæˆ {processed_regions} ä¸ªç‹¬ç«‹é«˜è´¨é‡åŒºåŸŸ")
    return result_mask

def advanced_separate_connected_objects(mask):
    """
    é«˜çº§åˆ†ç¦»æ–¹æ³•ï¼šç»“åˆå¤šç§å½¢æ€å­¦æ“ä½œï¼Œä¸ä¾èµ–é¢å¤–åº“
    """
    # æ–¹æ³•1: åŸºäºè…èš€-è†¨èƒ€çš„åˆ†ç¦»
    kernel_erode = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    eroded = cv2.erode(mask, kernel_erode, iterations=2)
    
    # å¯»æ‰¾è¿é€šåˆ†é‡
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(eroded, connectivity=8)
    
    if num_labels <= 1:  # æ²¡æœ‰æ‰¾åˆ°åˆ†ç¦»çš„åŒºåŸŸ
        print("âš ï¸ è…èš€åæœªæ‰¾åˆ°åˆ†ç¦»åŒºåŸŸï¼Œå°è¯•æ›´å¼ºçš„åˆ†ç¦»")
        return erosion_dilation_separation(mask)
    
    result_mask = np.zeros_like(mask)
    
    for i in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯
        # è·å–å½“å‰è¿é€šåˆ†é‡
        component_mask = (labels == i).astype(np.uint8) * 255
        
        # å¯¹æ¯ä¸ªåˆ†é‡è¿›è¡Œè†¨èƒ€æ¢å¤
        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        dilated = cv2.dilate(component_mask, kernel_dilate, iterations=2)
        
        # ä¸åŸå§‹maskå–äº¤é›†ï¼Œé¿å…è¿‡åº¦è†¨èƒ€
        dilated = cv2.bitwise_and(dilated, mask)
        
        result_mask = cv2.bitwise_or(result_mask, dilated)
    
    print(f"âœ… è…èš€-è†¨èƒ€åˆ†ç¦»å®Œæˆï¼Œç”Ÿæˆ {num_labels-1} ä¸ªåŒºåŸŸ")
    return result_mask

def erosion_dilation_separation(mask):
    """
    æ¸è¿›å¼è…èš€åˆ†ç¦»ç®—æ³•
    """
    original_mask = mask.copy()
    best_result = mask.copy()
    max_components = 1
    
    # å°è¯•ä¸åŒå¼ºåº¦çš„è…èš€
    for iterations in range(1, 6):
        for kernel_size in [(3,3), (5,5), (7,7)]:
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)
            eroded = cv2.erode(original_mask, kernel, iterations=iterations)
            
            # æ£€æŸ¥è¿é€šåˆ†é‡
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(eroded, connectivity=8)
            
            if num_labels > max_components:
                max_components = num_labels
                # æ¢å¤å„ä¸ªåˆ†é‡
                result_mask = np.zeros_like(mask)
                
                for i in range(1, num_labels):
                    component_mask = (labels == i).astype(np.uint8) * 255
                    
                    # è†¨èƒ€æ¢å¤ï¼Œä½†é™åˆ¶åœ¨åŸå§‹åŒºåŸŸå†…
                    kernel_restore = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (iterations*2+1, iterations*2+1))
                    restored = cv2.dilate(component_mask, kernel_restore, iterations=iterations)
                    restored = cv2.bitwise_and(restored, original_mask)
                    
                    result_mask = cv2.bitwise_or(result_mask, restored)
                
                best_result = result_mask.copy()
    
    print(f"âœ… æ¸è¿›å¼åˆ†ç¦»å®Œæˆï¼Œæœ€å¤šåˆ†ç¦»å‡º {max_components-1} ä¸ªåŒºåŸŸ")
    return best_result

def choose_separation_method(mask):
    """
    æ™ºèƒ½é€‰æ‹©é«˜æ€§èƒ½åˆ†ç¦»æ–¹æ³•
    """
    # è®¡ç®—åˆå§‹è¿é€šåˆ†é‡æ•°
    num_labels_initial, _, _, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
    
    if num_labels_initial > 2:  # å·²ç»åˆ†ç¦»ï¼Œæ— éœ€å¤„ç†
        print("âœ… åŒºåŸŸå·²ç»åˆ†ç¦»ï¼Œæ— éœ€é¢å¤–å¤„ç†")
        return mask
    
    # åˆ†æå›¾åƒç‰¹å¾
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if len(contours) == 0:
        return mask
    
    # è®¡ç®—å¤šä¸ªå¤æ‚åº¦æŒ‡æ ‡
    total_area = sum(cv2.contourArea(c) for c in contours)
    total_perimeter = sum(cv2.arcLength(c, True) for c in contours)
    
    # å½¢çŠ¶å¤æ‚åº¦ï¼šå‘¨é•¿å¹³æ–¹/é¢ç§¯
    shape_complexity = (total_perimeter ** 2) / (total_area + 1e-6)
    
    # å‡¸æ€§åˆ†æ
    total_hull_area = sum(cv2.contourArea(cv2.convexHull(c)) for c in contours)
    convexity = total_area / (total_hull_area + 1e-6)
    
    # åŒºåŸŸç´§å‡‘åº¦
    compactness = (4 * np.pi * total_area) / (total_perimeter ** 2 + 1e-6)
    
    print(f"ğŸ” å›¾åƒåˆ†æç»“æœ:")
    print(f"   ğŸ“Š å½¢çŠ¶å¤æ‚åº¦: {shape_complexity:.2f}")
    print(f"   ğŸ”„ å‡¸æ€§ç³»æ•°: {convexity:.3f}")
    print(f"   ğŸ“ ç´§å‡‘åº¦: {compactness:.3f}")
    
    # æ™ºèƒ½é€‰æ‹©åˆ†ç¦»ç­–ç•¥
    try:
        # ä¼˜å…ˆä½¿ç”¨é«˜æ€§èƒ½çš„scikit-imageç®—æ³•
        if shape_complexity > 80 or convexity < 0.7:
            print("ğŸš€ ä½¿ç”¨è¶…å¼ºåˆ†ç¦»ç®—æ³•ï¼ˆå¤æ‚å½¢çŠ¶ï¼‰...")
            return ultra_separate_connected_objects(mask)
        elif compactness < 0.3:
            print("ğŸš€ ä½¿ç”¨è¶…å¼ºåˆ†ç¦»ç®—æ³•ï¼ˆéç´§å‡‘å½¢çŠ¶ï¼‰...")
            return ultra_separate_connected_objects(mask)
        else:
            print("âš¡ ä½¿ç”¨é«˜é€Ÿå½¢æ€å­¦æ–¹æ³•ï¼ˆç®€å•å½¢çŠ¶ï¼‰...")
            return advanced_separate_connected_objects(mask)
    except Exception as e:
        print(f"âš ï¸ é«˜æ€§èƒ½ç®—æ³•å¤±è´¥: {e}")
        print("ğŸ”„ å›é€€åˆ°ç¨³å®šçš„OpenCVæ–¹æ³•...")
        return advanced_separate_connected_objects(mask)

def show_separation_comparison(original_mask, processed_mask, image_path):
    """
    é«˜æ€§èƒ½åˆ†ç¦»æ•ˆæœå¯è§†åŒ–å¯¹æ¯”
    """
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # åŸå§‹å›¾åƒ
    img = cv2.imread(image_path)
    if img is not None:
        axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[0, 0].set_title("åŸå§‹å›¾åƒ", fontsize=14, fontweight='bold')
        axes[0, 0].axis('off')
    
    # åˆ†ç¦»å‰çš„mask
    axes[0, 1].imshow(original_mask, cmap='gray')
    axes[0, 1].set_title("åˆ†ç¦»å‰", fontsize=14, fontweight='bold')
    axes[0, 1].axis('off')
    
    # åˆ†ç¦»åçš„mask
    axes[0, 2].imshow(processed_mask, cmap='gray')
    axes[0, 2].set_title("åˆ†ç¦»å", fontsize=14, fontweight='bold')
    axes[0, 2].axis('off')
    
    # è½®å»“å¯¹æ¯” - åˆ†ç¦»å‰
    contours_before, _ = cv2.findContours(original_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_contours_before = cv2.cvtColor(original_mask, cv2.COLOR_GRAY2RGB)
    for i, contour in enumerate(contours_before):
        cv2.drawContours(img_contours_before, [contour], -1, (255, 0, 0), 2)
        # æ·»åŠ ç¼–å·
        M = cv2.moments(contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(img_contours_before, str(i+1), (cx-10, cy+5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
    
    axes[1, 0].imshow(img_contours_before)
    axes[1, 0].set_title("åˆ†ç¦»å‰è½®å»“", fontsize=14, fontweight='bold')
    axes[1, 0].axis('off')
    
    # è½®å»“å¯¹æ¯” - åˆ†ç¦»å
    contours_after, _ = cv2.findContours(processed_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_contours_after = cv2.cvtColor(processed_mask, cv2.COLOR_GRAY2RGB)
    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
    
    for i, contour in enumerate(contours_after):
        color = colors[i % len(colors)]
        cv2.drawContours(img_contours_after, [contour], -1, color, 2)
        # æ·»åŠ ç¼–å·
        M = cv2.moments(contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(img_contours_after, str(i+1), (cx-10, cy+5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    axes[1, 1].imshow(img_contours_after)
    axes[1, 1].set_title("åˆ†ç¦»åè½®å»“", fontsize=14, fontweight='bold')
    axes[1, 1].axis('off')
    
    # ç»Ÿè®¡ä¿¡æ¯å›¾è¡¨
    valid_before = len([c for c in contours_before if cv2.contourArea(c) > 100])
    valid_after = len([c for c in contours_after if cv2.contourArea(c) > 100])
    
    areas_before = [cv2.contourArea(c) for c in contours_before if cv2.contourArea(c) > 100]
    areas_after = [cv2.contourArea(c) for c in contours_after if cv2.contourArea(c) > 100]
    
    # é¢ç§¯å¯¹æ¯”æŸ±çŠ¶å›¾
    axes[1, 2].bar(['åˆ†ç¦»å‰', 'åˆ†ç¦»å'], [sum(areas_before), sum(areas_after)], 
                   color=['red', 'green'], alpha=0.7)
    axes[1, 2].set_title("æ€»é¢ç§¯å¯¹æ¯”", fontsize=14, fontweight='bold')
    axes[1, 2].set_ylabel("é¢ç§¯ (åƒç´ )")
    
    # åœ¨å›¾ä¸Šæ·»åŠ æ•°å€¼
    for i, v in enumerate([sum(areas_before), sum(areas_after)]):
        axes[1, 2].text(i, v + max(areas_before + areas_after) * 0.02, f'{int(v)}', 
                        ha='center', va='bottom', fontweight='bold')
    
    # åˆ†ç¦»æ•ˆæœä¿¡æ¯
    improvement_ratio = valid_after / max(valid_before, 1)
    separation_info = f'''åˆ†ç¦»æ€§èƒ½æŠ¥å‘Š:
    â”œâ”€ åŒºåŸŸæ•°é‡: {valid_before} â†’ {valid_after}
    â”œâ”€ æå‡å€æ•°: {improvement_ratio:.2f}x
    â”œâ”€ æ€»é¢ç§¯: {sum(areas_before):.0f} â†’ {sum(areas_after):.0f}
    â””â”€ å¹³å‡é¢ç§¯: {np.mean(areas_before):.0f} â†’ {np.mean(areas_after):.0f}'''
    
    fig.suptitle(f'ğŸš€ é«˜æ€§èƒ½åˆ†ç¦»æ•ˆæœå¯¹æ¯”\n{separation_info}', 
                fontsize=16, fontweight='bold', y=0.02)
    plt.tight_layout()
    plt.subplots_adjust(top=0.85)
    plt.show()
    
    print(f"\nğŸ¯ åˆ†ç¦»æ€§èƒ½æ€»ç»“:")
    print(f"   ğŸ”¢ åŒºåŸŸæ•°é‡å˜åŒ–: {valid_before} â†’ {valid_after}")
    print(f"   ğŸ“ˆ åˆ†ç¦»æ•ˆæœæå‡: {improvement_ratio:.2f}å€")
    print(f"   ğŸ“Š é¢ç§¯ä¿æŒç‡: {sum(areas_after)/sum(areas_before)*100:.1f}%")

def save_features_only(valid_contours, tooth_id, features_dir="templates/features"):
    from pathlib import Path
    import numpy as np

    def to_serializable(feat):
        # æŠŠæ‰€æœ‰ ndarray è½¬æˆ list
        if isinstance(feat, np.ndarray):
            return feat.tolist()
        if isinstance(feat, dict):
            return {k: to_serializable(v) for k, v in feat.items()}
        if isinstance(feat, list):
            return [to_serializable(x) for x in feat]
        return feat

    features_dir = Path(features_dir)
    features_dir.mkdir(parents=True, exist_ok=True)
    features_list = [to_serializable(contour['features']) for contour in valid_contours]
    features_path = features_dir / f"{tooth_id}_features.json"
    with open(features_path, 'w', encoding='utf-8') as f:
        json.dump({"features": features_list}, f, ensure_ascii=False, indent=2)
    print(f"âœ… çº¯ç‰¹å¾æ–‡ä»¶å·²ä¿å­˜: {features_path}")


def main():
    """
    é«˜æ€§èƒ½ç‰™é½¿æ¨¡æ¿å»ºç«‹å™¨ä¸»ç¨‹åº - æ”¯æŒå•å¼ å’Œæ‰¹é‡å¤„ç†
    """
    parser = argparse.ArgumentParser(description='ç‰™é½¿æ¨¡æ¿å»ºç«‹å™¨')
    parser.add_argument('--batch', action='store_true', help='å¯ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼')
    parser.add_argument('--input-dir', default='images', help='è¾“å…¥ç›®å½•è·¯å¾„ (é»˜è®¤: images)')
    parser.add_argument('--output-dir', default='templates', help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: templates)')
    parser.add_argument('--database', default='tooth_templates.db', help='æ•°æ®åº“è·¯å¾„ (é»˜è®¤: tooth_templates.db)')
    parser.add_argument('--skip-processed', action='store_true', default=True, 
                       help='è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶ (é»˜è®¤: True)')
    parser.add_argument('--single-image', help='å¤„ç†å•å¼ å›¾åƒçš„è·¯å¾„')
    
    args = parser.parse_args()
    
    if args.batch:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        print("ğŸš€ å¯åŠ¨æ‰¹é‡ç‰™é½¿æ¨¡æ¿å»ºç«‹å™¨")
        print("=" * 60)
        
        processor = BatchToothProcessor(
            input_dir=args.input_dir,
            templates_dir=args.output_dir,
            database_path=args.database
        )
        
        try:
            report = processor.process_batch(
                skip_processed=args.skip_processed,
                interactive_first=True,
                show_progress=True
            )
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            if report['processed'] > 0:
                print(f"\nğŸ¯ æ‰¹é‡å¤„ç†æˆåŠŸå®Œæˆ!")
                print(f"âœ… å·²åˆ›å»º {report['processed']} ä¸ªç‰™é½¿æ¨¡æ¿")
                
                # æ˜¾ç¤ºå·²ä¿å­˜çš„æ¨¡æ¿åˆ—è¡¨
                processor.builder.list_templates()
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            print("ğŸ’¡ è¯·æ£€æŸ¥è¾“å…¥ç›®å½•å’Œæ–‡ä»¶æƒé™")
    
    elif args.single_image:
        # å•å¼ å›¾åƒå¤„ç†æ¨¡å¼
        print("ğŸš€ å¯åŠ¨å•å¼ å›¾åƒå¤„ç†æ¨¡å¼")
        print("=" * 50)
        
        image_path = args.single_image
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return
        
        print(f"ğŸ“¸ æ­£åœ¨å¤„ç†å›¾åƒ: {image_path}")
        
        try:
            pick_color_and_draw_edge(image_path, tooth_id=None)
            print("\nğŸ‰ å•å¼ å›¾åƒå¤„ç†å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            
    else:
        # é»˜è®¤å•å¼ å¤„ç†æ¨¡å¼ï¼ˆä½¿ç”¨PHOTO_PATHï¼‰
        print("ğŸš€ å¯åŠ¨é«˜æ€§èƒ½ç‰™é½¿æ¨¡æ¿å»ºç«‹å™¨")
        print("=" * 50)
        
        # è‡ªåŠ¨ç”Ÿæˆè¿ç»­ç¼–å·ï¼Œæ— éœ€ç”¨æˆ·è¾“å…¥
        tooth_id = None  # å°†è‡ªåŠ¨ç”Ÿæˆ TOOTH_001, TOOTH_002...
        
        # å›¾åƒè·¯å¾„
        image_path = PHOTO_PATH 
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            print("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print(f"ğŸ’¡ æˆ–ä½¿ç”¨ --single-image æŒ‡å®šå›¾åƒè·¯å¾„")
            print(f"ğŸ’¡ æˆ–ä½¿ç”¨ --batch --input-dir æŒ‡å®šæ‰¹é‡å¤„ç†ç›®å½•")
            return
        
        print(f"ğŸ“¸ æ­£åœ¨å¤„ç†å›¾åƒ: {image_path}")
        
        try:
            # å¯åŠ¨é«˜æ€§èƒ½åˆ†ç¦»å’Œæ¨¡æ¿å»ºç«‹ï¼ˆè‡ªåŠ¨ä¿å­˜ï¼‰
            pick_color_and_draw_edge(image_path, tooth_id)
            print("\nğŸ‰ é«˜æ€§èƒ½å¤„ç†å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            print("ğŸ’¡ è¯·æ£€æŸ¥å›¾åƒæ–‡ä»¶å’Œä¾èµ–åº“æ˜¯å¦æ­£ç¡®å®‰è£…")

def main_batch_example():
    """æ‰¹å¤„ç†ç¤ºä¾‹ - æ¼”ç¤ºå¤šä¸ªå›¾ç‰‡çš„å¤„ç†"""
    processor = BatchToothProcessor(
        input_dir="images",
        templates_dir="templates",
        database_path="tooth_templates.db"
    )
    
    processor.process_batch(skip_processed=True)

def test_calibration_system():
    """æµ‹è¯•æ ‡å®šç³»ç»Ÿçš„åŠŸèƒ½"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•æ ‡å®šç³»ç»Ÿ...")
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„æ¨¡æ¿æ„å»ºå™¨
    builder = ToothTemplateBuilder()
    
    # æµ‹è¯•æ ‡å®šç‰©æ£€æµ‹
    test_image_path = "images/test_tooth.jpg"  # ç¡®ä¿è¿™ä¸ªè·¯å¾„å­˜åœ¨
    if os.path.exists(test_image_path):
        logger.info(f"ğŸ“¸ æµ‹è¯•å›¾åƒ: {test_image_path}")
        
        # åŠ è½½å›¾åƒ
        img = cv2.imread(test_image_path)
        if img is not None:
            # æ‰§è¡Œæ ‡å®šæ£€æµ‹
            calibration_result = builder.reference_detector.detect_reference_object(img)
            
            if calibration_result.pixel_per_mm > 0:
                logger.info(f"âœ… æ ‡å®šæµ‹è¯•æˆåŠŸ!")
                logger.info(f"   åƒç´ æ¯”ä¾‹: {calibration_result.pixel_per_mm:.4f} px/mm")
                logger.info(f"   ç½®ä¿¡åº¦: {calibration_result.confidence:.3f}")
                logger.info(f"   å‚è€ƒç‰©ä½ç½®: {calibration_result.reference_position}")
                
                # æµ‹è¯•ç‰¹å¾å½’ä¸€åŒ–å™¨
                normalizer = PhysicalFeatureNormalizer(
                    calibration_result.pixel_per_mm,
                    calibration_result.confidence
                )
                
                # åˆ›å»ºæµ‹è¯•ç‰¹å¾
                test_features = {
                    'area': 10000.0,  # åƒç´ Â²
                    'perimeter': 400.0,  # åƒç´ 
                    'bounding_rect': (100, 200, 50, 80)  # x, y, w, h
                }
                
                # æµ‹è¯•å½’ä¸€åŒ–
                normalized_features = normalizer.normalize_geometric_features(test_features)
                
                logger.info(f"ğŸ”¬ ç‰¹å¾å½’ä¸€åŒ–æµ‹è¯•:")
                logger.info(f"   åŸå§‹é¢ç§¯: {test_features['area']:.0f} pxÂ²")
                logger.info(f"   å½’ä¸€åŒ–é¢ç§¯: {normalized_features.get('area_mm2', 0):.2f} mmÂ²")
                logger.info(f"   åŸå§‹å‘¨é•¿: {test_features['perimeter']:.0f} px")
                logger.info(f"   å½’ä¸€åŒ–å‘¨é•¿: {normalized_features.get('perimeter_mm', 0):.2f} mm")
                
                return True
            else:
                logger.warning(f"âŒ æ ‡å®šæµ‹è¯•å¤±è´¥: {calibration_result.error_message}")
                return False
        else:
            logger.error(f"âŒ æ— æ³•åŠ è½½æµ‹è¯•å›¾åƒ: {test_image_path}")
            return False
    else:
        logger.warning(f"âš ï¸ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image_path}")
        logger.info("ğŸ’¡ è¯·å°†åŒ…å«134mmÃ—9mmé•¿æ–¹å½¢æ ‡å®šç‰©çš„å›¾åƒæ”¾ç½®åœ¨imagesç›®å½•ä¸‹")
        return False

def show_database_status():
    """æ˜¾ç¤ºæ•°æ®åº“çŠ¶æ€å’Œç»Ÿè®¡ä¿¡æ¯"""
    builder = ToothTemplateBuilder()
    
    logger.info("ğŸ“Š æ•°æ®åº“çŠ¶æ€æŠ¥å‘Š:")
    logger.info("=" * 50)
    
    conn = sqlite3.connect(builder.database_path)
    cursor = conn.cursor()
    
    try:
        # ç»Ÿè®¡æ¨¡æ¿æ•°é‡
        cursor.execute("SELECT COUNT(*) FROM templates")
        total_templates = cursor.fetchone()[0]
        logger.info(f"ğŸ“‹ æ€»æ¨¡æ¿æ•°: {total_templates}")
        
        # ç»Ÿè®¡å½’ä¸€åŒ–æ¨¡æ¿æ•°é‡
        cursor.execute("SELECT COUNT(*) FROM templates WHERE is_normalized = 1")
        normalized_templates = cursor.fetchone()[0]
        logger.info(f"ğŸ”¬ å½’ä¸€åŒ–æ¨¡æ¿æ•°: {normalized_templates}")
        
        # ç»Ÿè®¡ä¼ ç»Ÿæ¨¡æ¿æ•°é‡
        traditional_templates = total_templates - normalized_templates
        logger.info(f"ğŸ“ ä¼ ç»Ÿæ¨¡æ¿æ•°: {traditional_templates}")
        
        # æ ‡å®šè®°å½•ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM calibration_records")
        calibration_records = cursor.fetchone()[0]
        logger.info(f"ğŸ“ æ ‡å®šè®°å½•æ•°: {calibration_records}")
        
        # ç‰©ç†ç‰¹å¾è®°å½•ç»Ÿè®¡
        cursor.execute("SELECT COUNT(*) FROM physical_features")
        physical_features = cursor.fetchone()[0]
        logger.info(f"ğŸ”¬ ç‰©ç†ç‰¹å¾è®°å½•æ•°: {physical_features}")
        
        # æœ€è¿‘çš„æ¨¡æ¿
        cursor.execute("""
            SELECT tooth_id, created_at, is_normalized, pixel_per_mm 
            FROM templates 
            ORDER BY created_at DESC 
            LIMIT 5
        """)
        recent_templates = cursor.fetchall()
        
        if recent_templates:
            logger.info("\nğŸ“… æœ€è¿‘çš„æ¨¡æ¿:")
            for tooth_id, created_at, is_normalized, pixel_per_mm in recent_templates:
                status = "å½’ä¸€åŒ–" if is_normalized else "ä¼ ç»Ÿ"
                scale_info = f"({pixel_per_mm:.3f} px/mm)" if pixel_per_mm else ""
                logger.info(f"   {tooth_id} - {status} {scale_info} - {created_at}")
        
    except sqlite3.Error as e:
        logger.error(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")
    finally:
        conn.close()

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="ç‰™é½¿æ¨¡æ¿æ„å»ºå·¥å…· - é›†æˆæ ‡å®šåŠŸèƒ½")
    parser.add_argument('--mode', choices=['single', 'batch', 'test', 'status'], 
                       default='single', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--image', help='å•ä¸ªå›¾åƒè·¯å¾„ (singleæ¨¡å¼)')
    parser.add_argument('--input-dir', default='images', help='è¾“å…¥ç›®å½•è·¯å¾„ (batchæ¨¡å¼)')
    parser.add_argument('--output-dir', default='templates', help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--database', default='tooth_templates.db', help='æ•°æ®åº“è·¯å¾„')
    parser.add_argument('--tooth-id', help='æŒ‡å®šç‰™é½¿ID')
    
    args = parser.parse_args()
    
    if args.mode == 'single':
        if args.image and os.path.exists(args.image):
            logger.info(f"ğŸ¦· å•å›¾åƒå¤„ç†æ¨¡å¼: {args.image}")
            pick_color_and_draw_edge(args.image, args.tooth_id)
        else:
            logger.info("ğŸ¦· äº¤äº’å¼å•å›¾åƒå¤„ç†æ¨¡å¼")
            # é»˜è®¤å›¾åƒè·¯å¾„
            image_path = PHOTO_PATH
            if not os.path.exists(image_path):
                # å°è¯•æ‰¾åˆ°ä»»æ„å›¾åƒ
                image_files = []
                for ext in ['*.jpg', '*.jpeg', '*.png']:
                    image_files.extend(glob.glob(f"images/{ext}"))
                
                if image_files:
                    image_path = image_files[0]
                    logger.info(f"ä½¿ç”¨å›¾åƒ: {image_path}")
                else:
                    logger.error("âŒ æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼Œè¯·åœ¨imagesç›®å½•ä¸­æ”¾ç½®å›¾åƒ")
                    exit(1)
            
            pick_color_and_draw_edge(image_path, args.tooth_id)
    
    elif args.mode == 'batch':
        logger.info(f"ğŸ“ æ‰¹å¤„ç†æ¨¡å¼: {args.input_dir} -> {args.output_dir}")
        processor = BatchToothProcessor(
            input_dir=args.input_dir,
            templates_dir=args.output_dir,
            database_path=args.database
        )
        processor.process_batch(skip_processed=True)
    
    elif args.mode == 'test':
        logger.info("ğŸ§ª æµ‹è¯•æ¨¡å¼")
        success = test_calibration_system()
        if success:
            logger.info("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
        else:
            logger.error("âŒ æµ‹è¯•å¤±è´¥")
            exit(1)
    
    elif args.mode == 'status':
        logger.info("ğŸ“Š çŠ¶æ€æŸ¥çœ‹æ¨¡å¼")
        show_database_status()
    
    logger.info("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆ")

    @staticmethod
    def fit_fourier_series(data: np.ndarray, t: np.ndarray, order: int) -> np.ndarray:
        try:
            A = np.ones((len(t), 2 * order + 1))
            for k in range(1, order + 1):
                A[:, 2 * k - 1] = np.cos(k * t)
                A[:, 2 * k] = np.sin(k * t)
            coeffs, _, _, _ = lstsq(A, data, rcond=None)
            return coeffs
        except Exception as e:
            logger.error(f"å‚…é‡Œå¶çº§æ•°æ‹Ÿåˆå¤±è´¥: {e}")
            return np.zeros(2 * order + 1)

    @staticmethod
    def evaluate_fourier_series(coeffs: np.ndarray, t: np.ndarray, order: int) -> np.ndarray:
        A = np.ones((len(t), 2 * order + 1))
        for k in range(1, order + 1):
            A[:, 2 * k - 1] = np.cos(k * t)
            A[:, 2 * k] = np.sin(k * t)
        return A @ coeffs

    def analyze_contour(self, points: np.ndarray, order: int = 80, center_normalize: bool = True) -> dict:
        try:
            x = points[:, 0].astype(float)
            y = points[:, 1].astype(float)
            center_x = np.mean(x)
            center_y = np.mean(y)
            if center_normalize:
                x_normalized = x - center_x
                y_normalized = y - center_y
                max_dist = np.max(np.sqrt(x_normalized**2 + y_normalized**2))
                if max_dist > 0:
                    x_normalized /= max_dist
                    y_normalized /= max_dist
            else:
                x_normalized = x
                y_normalized = y
                max_dist = 1.0
            N = len(points)
            t = np.linspace(0, 2 * np.pi, N)
            coeffs_x = self.fit_fourier_series(x_normalized, t, order)
            coeffs_y = self.fit_fourier_series(y_normalized, t, order)
            t_dense = np.linspace(0, 2 * np.pi, N * 4)
            x_fit_normalized = self.evaluate_fourier_series(coeffs_x, t_dense, order)
            y_fit_normalized = self.evaluate_fourier_series(coeffs_y, t_dense, order)
            if center_normalize:
                x_fit = x_fit_normalized * max_dist + center_x
                y_fit = y_fit_normalized * max_dist + center_y
            else:
                x_fit = x_fit_normalized
                y_fit = y_fit_normalized
            return {
                'coeffs_x': coeffs_x,
                'coeffs_y': coeffs_y,
                'center_x': center_x,
                'center_y': center_y,
                'max_dist': max_dist,
                'order': order,
                'x_fit': x_fit,
                'y_fit': y_fit,
                'original_points': (x, y)
            }
        except Exception as e:
            logger.error(f"å‚…é‡Œå¶åˆ†æå¤±è´¥: {e}")
            return {}  # ä¿®æ­£ï¼šå§‹ç»ˆè¿”å›dict

class ContourFeatureExtractor:
    def __init__(self):
        self.fourier_analyzer = FourierAnalyzer()

    def extract_geometric_features(self, contour: np.ndarray, image_shape=None) -> dict:
        features = {}
        area = cv2.contourArea(contour)
        perimeter = cv2.arcLength(contour, True)
        if image_shape is not None:
            h, w = image_shape[:2]
            diag = (h**2 + w**2) ** 0.5
            area_norm = area / (diag ** 2)
            perimeter_norm = perimeter / diag
        else:
            area_norm = area
            perimeter_norm = perimeter
        x, y, w_box, h_box = cv2.boundingRect(contour)
        aspect_ratio = w_box / h_box if h_box != 0 else 0
        circularity = (4 * np.pi * area) / (perimeter * perimeter) if perimeter != 0 else 0
        hull = cv2.convexHull(contour)
        hull_area = cv2.contourArea(hull)
        solidity = area / hull_area if hull_area != 0 else 0
        epsilon = 0.02 * perimeter
        approx = cv2.approxPolyDP(contour, epsilon, True)
        corner_count = len(approx)
        features.update({
            'area': area,
            'perimeter': perimeter,
            'area_norm': area_norm,
            'perimeter_norm': perimeter_norm,
            'aspect_ratio': aspect_ratio,
            'circularity': circularity,
            'solidity': solidity,
            'corner_count': corner_count,
            'bounding_rect': (x, y, w_box, h_box)
        })
        return features

    def extract_hu_moments(self, contour: np.ndarray) -> np.ndarray:
        try:
            moments = cv2.moments(contour)
            hu_moments = cv2.HuMoments(moments).flatten()
            for i in range(len(hu_moments)):
                if hu_moments[i] != 0:
                    hu_moments[i] = -1 * np.copysign(1.0, hu_moments[i]) * np.log10(abs(hu_moments[i]))
                else:
                    hu_moments[i] = 0
            return hu_moments
        except Exception as e:
            logger.error(f"HuçŸ©è®¡ç®—å¤±è´¥: {e}")
            return np.zeros(7)

    def extract_fourier_descriptors(self, points: np.ndarray) -> np.ndarray:
        try:
            fourier_data = self.fourier_analyzer.analyze_contour(points, center_normalize=True)
            if fourier_data is not None:
                coeffs_x = fourier_data['coeffs_x']
                coeffs_y = fourier_data['coeffs_y']
                fourier_features = np.concatenate([coeffs_x[:11], coeffs_y[:11]])
                return fourier_features
            else:
                return np.zeros(22)
        except Exception as e:
            logger.error(f"å‚…é‡Œå¶æè¿°ç¬¦æå–å¤±è´¥: {e}")
            return np.zeros(22)

    def extract_all_features(self, contour: np.ndarray, points: np.ndarray, image_shape=None) -> dict:
        features = {}
        geometric_features = self.extract_geometric_features(contour, image_shape=image_shape)
        features.update(geometric_features)
        features['hu_moments'] = self.extract_hu_moments(contour)
        features['fourier_descriptors'] = self.extract_fourier_descriptors(points)
        fourier_data = self.fourier_analyzer.analyze_contour(points, center_normalize=True)
        if fourier_data is not None:
            features['fourier_x_fit'] = fourier_data['x_fit'].tolist()
            features['fourier_y_fit'] = fourier_data['y_fit'].tolist()
        return features

matplotlib.rcParams['font.sans-serif'] = ['SimHei']  # é»‘ä½“
matplotlib.rcParams['axes.unicode_minus'] = False

class ToothTemplateBuilder:
    def __init__(self, database_path="tooth_templates.db", templates_dir="templates"):
        self.database_path = database_path
        self.templates_dir = Path(templates_dir)
        self.templates_dir.mkdir(exist_ok=True)
        (self.templates_dir / "contours").mkdir(exist_ok=True)
        (self.templates_dir / "images").mkdir(exist_ok=True)
        self.init_database()
        self.feature_extractor = ContourFeatureExtractor()
        self.current_image = None  # type: ignore  # ä¿®æ­£ï¼šå…è®¸åŠ¨æ€ç±»å‹
    
    def init_database(self):
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS templates (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tooth_id TEXT UNIQUE NOT NULL,
                name TEXT,
                image_path TEXT,
                contour_file TEXT,
                num_contours INTEGER,
                total_area REAL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        conn.commit()
        conn.close()
        print(f"âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.database_path}")

    def get_next_tooth_id(self):
        """ç”Ÿæˆä¸‹ä¸€ä¸ªè¿ç»­çš„ç‰™æ¨¡ç¼–å·"""
        contours_dir = self.templates_dir / "contours"
        if not contours_dir.exists():
            return "TOOTH_001"
        
        existing_files = list(contours_dir.glob("TOOTH_*.json"))
        if not existing_files:
            return "TOOTH_001"
        
        # æå–ç¼–å·å¹¶æ‰¾åˆ°æœ€å¤§å€¼
        max_num = 0
        for file in existing_files:
            try:
                num_str = file.stem.split('_')[1]  # TOOTH_001 -> 001
                num = int(num_str)
                max_num = max(max_num, num)
            except (IndexError, ValueError):
                continue
        
        return f"TOOTH_{max_num + 1:03d}"

    def serialize_contours(self, valid_contours, tooth_id=None, image_path=None, hsv_info=None, auto_save=False):
        """åºåˆ—åŒ–è½®å»“æ•°æ®
        Args:
            valid_contours: æœ‰æ•ˆè½®å»“åˆ—è¡¨
            tooth_id: ç‰™æ¨¡IDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            image_path: å›¾åƒè·¯å¾„
            hsv_info: HSVé¢œè‰²ä¿¡æ¯
            auto_save: æ˜¯å¦è‡ªåŠ¨ä¿å­˜ï¼ˆæ— éœ€ç”¨æˆ·ç¡®è®¤ï¼‰
        """
        try:
            if tooth_id is None:
                tooth_id = self.get_next_tooth_id()
            
            template_data = {
                "tooth_id": tooth_id,
                "image_path": str(image_path) if image_path else None,
                "created_at": datetime.now().isoformat(),
                "hsv_info": hsv_info,
                "num_contours": len(valid_contours),
                "contours": []
            }
            
            total_area = 0
            for i, contour_info in enumerate(valid_contours):
                points = contour_info['points']
                contour = contour_info['contour']
                x, y, w, h = cv2.boundingRect(contour)
                # === æ–°å¢ï¼šæå–é«˜çº§ç‰¹å¾ ===
                features = self.feature_extractor.extract_all_features(contour, points, image_shape=self.current_image.shape if hasattr(self, 'current_image') and self.current_image is not None else None)
                contour_info['features'] = features  # â˜…â˜…â˜… å…³é”®ï¼šåŠ ä¸Šè¿™ä¸€è¡Œ
                contour_data = {
                    "idx": i,
                    "original_idx": contour_info['idx'],
                    "points": points.tolist(),
                    "area": float(contour_info['area']),
                    "perimeter": float(contour_info['length']),
                    "bounding_box": {"x": int(x), "y": int(y), "width": int(w), "height": int(h)},
                    "features": {
                        "area": float(features['area']),
                        "perimeter": float(features['perimeter']),
                        "area_norm": float(features['area_norm']),
                        "perimeter_norm": float(features['perimeter_norm']),
                        "aspect_ratio": float(features['aspect_ratio']),
                        "circularity": float(features['circularity']),
                        "solidity": float(features['solidity']),
                        "corner_count": int(features['corner_count']),
                        "hu_moments": features['hu_moments'].tolist(),
                        "fourier_descriptors": features['fourier_descriptors'].tolist()
                    }
                }
                template_data["contours"].append(contour_data)
                total_area += contour_info['area']
            
            template_data["total_area"] = float(total_area)
            
            # ä¿å­˜JSONæ–‡ä»¶
            json_filename = f"{tooth_id}.json"
            json_path = self.templates_dir / "contours" / json_filename
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(template_data, f, ensure_ascii=False, indent=2)

            # === æ–°å¢ï¼šä¿å­˜ç‰¹å¾æ–‡ä»¶åˆ° features ç›®å½• ===
            save_features_only(valid_contours, tooth_id)
            
            # åŒæ—¶ä¿å­˜è½®å»“å›¾åƒï¼ˆPNGæ ¼å¼ï¼‰
            png_filename = f"{tooth_id}.png"
            png_path = self.templates_dir / "images" / png_filename
            png_path.parent.mkdir(exist_ok=True)
            
            # åˆ›å»ºè½®å»“å›¾åƒ
            if hasattr(self, 'current_image') and self.current_image is not None:
                contour_img = self.current_image.copy()
                for contour_info in valid_contours:
                    cv2.drawContours(contour_img, [contour_info['contour']], -1, (0, 255, 0), 2)
                cv2.imwrite(str(png_path), contour_img)
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self.save_to_database(template_data, json_filename, image_path)
            
            save_type = "è‡ªåŠ¨ä¿å­˜" if auto_save else "æ‰‹åŠ¨ä¿å­˜"
            print(f"âœ… æ¨¡æ¿å·²{save_type}: {tooth_id} ({len(valid_contours)}ä¸ªè½®å»“)")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
            return False
    
    def save_to_database(self, template_data, json_filename, image_path):
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        try:
            cursor.execute('''
                INSERT OR REPLACE INTO templates 
                (tooth_id, name, image_path, contour_file, num_contours, total_area)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                template_data["tooth_id"],
                f"ç‰™é½¿æ¨¡å‹ {template_data['tooth_id']}",
                image_path,
                json_filename,
                template_data["num_contours"],
                template_data["total_area"]
            ))
            conn.commit()
            print(f"âœ… æ•°æ®åº“è®°å½•å·²ä¿å­˜")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
        finally:
            conn.close()

    def list_templates(self):
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        cursor.execute('SELECT tooth_id, num_contours, total_area, created_at FROM templates ORDER BY created_at DESC')
        templates = cursor.fetchall()
        conn.close()
        
        if templates:
            print("\nğŸ“‹ å·²ä¿å­˜çš„ç‰™é½¿æ¨¡æ¿:")
            print("-" * 50)
            for tooth_id, num_contours, total_area, created_at in templates:
                print(f"ID: {tooth_id:<15} | è½®å»“: {num_contours:<3} | é¢ç§¯: {total_area:<8.1f}")
        else:
            print("ğŸ“­ æš‚æ— ä¿å­˜çš„æ¨¡æ¿")
        return templates

    def load_saved_contours(self, tooth_id):
        """åŠ è½½å·²ä¿å­˜çš„è½®å»“æ•°æ®ç”¨äºæ¯”å¯¹
        Args:
            tooth_id: ç‰™æ¨¡ID
        Returns:
            dict: åŒ…å«è½®å»“ä¿¡æ¯çš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        json_path = self.templates_dir / "contours" / f"{tooth_id}.json"
        if not json_path.exists():
            print(f"âŒ æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {tooth_id}")
            return None
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                template_data = json.load(f)
            print(f"âœ… æˆåŠŸåŠ è½½æ¨¡æ¿: {tooth_id}")
            return template_data
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡æ¿å¤±è´¥: {e}")
            return None

    def compare_with_saved_template(self, current_contours, template_tooth_id):
        """ç®€å•çš„è½®å»“æ¯”å¯¹ç¤ºä¾‹
        Args:
            current_contours: å½“å‰æ£€æµ‹åˆ°çš„è½®å»“åˆ—è¡¨
            template_tooth_id: è¦æ¯”å¯¹çš„æ¨¡æ¿ID
        Returns:
            dict: æ¯”å¯¹ç»“æœ
        """
        template_data = self.load_saved_contours(template_tooth_id)
        if not template_data:
            return {"success": False, "error": "æ— æ³•åŠ è½½æ¨¡æ¿"}
        
        current_count = len(current_contours)
        template_count = template_data['num_contours']
        
        # ç®€å•çš„æ•°é‡å’Œé¢ç§¯æ¯”å¯¹
        current_total_area = sum(info['area'] for info in current_contours)
        template_total_area = template_data['total_area']
        
        area_similarity = min(current_total_area, template_total_area) / max(current_total_area, template_total_area)
        count_match = current_count == template_count
        
        result = {
            "success": True,
            "template_id": template_tooth_id,
            "current_count": current_count,
            "template_count": template_count,
            "count_match": count_match,
            "current_area": current_total_area,
            "template_area": template_total_area,
            "area_similarity": area_similarity,
            "is_similar": area_similarity > 0.8 and count_match
        }
        
        print(f"\nğŸ“Š è½®å»“æ¯”å¯¹ç»“æœ:")
        print(f"   æ¨¡æ¿ID: {template_tooth_id}")
        print(f"   è½®å»“æ•°é‡: {current_count} vs {template_count} ({'âœ… åŒ¹é…' if count_match else 'âŒ ä¸åŒ¹é…'})")
        print(f"   æ€»é¢ç§¯: {current_total_area:.1f} vs {template_total_area:.1f}")
        print(f"   é¢ç§¯ç›¸ä¼¼åº¦: {area_similarity:.3f}")
        print(f"   æ•´ä½“ç›¸ä¼¼: {'âœ… æ˜¯' if result['is_similar'] else 'âŒ å¦'}")
        
        return result

    def list_all_saved_templates(self):
        """åˆ—å‡ºæ‰€æœ‰å·²ä¿å­˜çš„æ¨¡æ¿ID"""
        contours_dir = self.templates_dir / "contours"
        if not contours_dir.exists():
            return []
        
        template_files = list(contours_dir.glob("TOOTH_*.json"))
        template_ids = [f.stem for f in template_files]
        
        if template_ids:
            print(f"\nğŸ“ æ‰¾åˆ° {len(template_ids)} ä¸ªå·²ä¿å­˜æ¨¡æ¿:")
            for tid in sorted(template_ids):
                print(f"   - {tid}")
        
        return sorted(template_ids)

class BatchToothProcessor:
    """æ‰¹é‡ç‰™é½¿å›¾åƒå¤„ç†å™¨ - åŸºäºç°æœ‰çš„ToothTemplateBuilder"""
    
    def __init__(self, input_dir: str = "images", templates_dir: str = "templates", 
                 database_path: str = "tooth_templates.db"):
        self.input_dir = Path(input_dir)
        self.templates_dir = Path(templates_dir)
        self.database_path = database_path
        self.builder = ToothTemplateBuilder(database_path, str(templates_dir))
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        self.supported_formats = {'.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif'}
        
        # æ‰¹é‡å¤„ç†çŠ¶æ€
        self.processed_files: List[str] = []
        self.failed_files: List[Tuple[str, str]] = []  # (æ–‡ä»¶å, é”™è¯¯ä¿¡æ¯)
        self.skipped_files: List[str] = []
        
        # é¢œè‰²æ¨¡æ¿ç¼“å­˜
        self.color_template: Optional[Dict] = None
        
        print(f"ğŸš€ æ‰¹é‡å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ğŸ“ è¾“å…¥ç›®å½•: {self.input_dir}")
        print(f"   ğŸ“„ æ¨¡æ¿ç›®å½•: {self.templates_dir}")
        print(f"   ğŸ—„ï¸ æ•°æ®åº“: {self.database_path}")
    
    def scan_image_files(self) -> List[Path]:
        """æ‰«æè¾“å…¥ç›®å½•ä¸­çš„æ‰€æœ‰æ”¯æŒçš„å›¾åƒæ–‡ä»¶"""
        if not self.input_dir.exists():
            raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {self.input_dir}")
        
        image_files = []
        for ext in self.supported_formats:
            pattern = str(self.input_dir / f"*{ext}")
            image_files.extend(glob.glob(pattern))
            pattern = str(self.input_dir / f"*{ext.upper()}")
            image_files.extend(glob.glob(pattern))
        
        image_files = [Path(f) for f in image_files]
        image_files = sorted(set(image_files))  # å»é‡å¹¶æ’åº
        
        print(f"ğŸ“¸ å‘ç° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶:")
        for i, file in enumerate(image_files[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"   {i:2d}. {file.name}")
        if len(image_files) > 10:
            print(f"   ... è¿˜æœ‰ {len(image_files) - 10} ä¸ªæ–‡ä»¶")
        
        return image_files
    
    def is_already_processed(self, image_path: Path) -> bool:
        """æ£€æŸ¥å›¾åƒæ˜¯å¦å·²ç»è¢«å¤„ç†è¿‡ï¼ˆé€šè¿‡æ•°æ®åº“æŸ¥è¯¢ï¼‰"""
        conn = sqlite3.connect(self.database_path)
        cursor = conn.cursor()
        try:
            cursor.execute('SELECT tooth_id FROM templates WHERE image_path = ?', (str(image_path),))
            result = cursor.fetchone()
            return result is not None
        except Exception:
            return False
        finally:
            conn.close()
    
    def get_color_template_from_first_image(self, first_image_path: Path) -> Optional[Dict]:
        """ä»ç¬¬ä¸€å¼ å›¾åƒè·å–é¢œè‰²æ¨¡æ¿ï¼ˆäº¤äº’å¼é€‰æ‹©ï¼‰"""
        print(f"\nğŸ¨ è¯·åœ¨ç¬¬ä¸€å¼ å›¾åƒä¸­é€‰æ‹©ç›®æ ‡é¢œè‰²:")
        print(f"ğŸ“¸ {first_image_path.name}")
        
        img = cv2.imread(str(first_image_path))
        if img is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {first_image_path}")
            return None
        
        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
        picked = []
        
        def on_mouse(event, x, y, flags, param):
            if event == cv2.EVENT_LBUTTONDOWN:
                color = hsv[y, x]
                print(f"é€‰ä¸­ç‚¹HSV: {color}")
                picked.append(color)
        
        cv2.imshow("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º, å¤šç‚¹é€‰æ‹©åæŒ‰ESC)", img)
        cv2.setMouseCallback("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º, å¤šç‚¹é€‰æ‹©åæŒ‰ESC)", on_mouse)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
        
        if not picked:
            print("âŒ æœªé€‰å–é¢œè‰²")
            return None
        
        # è®¡ç®—HSVå¹³å‡å€¼
        hsv_arr = np.array(picked)
        h_mean, s_mean, v_mean = np.mean(hsv_arr, axis=0).astype(int)
        
        # åˆ›å»ºé¢œè‰²æ¨¡æ¿
        color_template = {
            'h_mean': int(h_mean),
            's_mean': int(s_mean),
            'v_mean': int(v_mean),
            'lower': [0, 0, 0],  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
            'upper': [15, 60, 61],  # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´
            'picked_points': len(picked)
        }
        
        print(f"âœ… é¢œè‰²æ¨¡æ¿åˆ›å»ºæˆåŠŸ:")
        print(f"   HSVå‡å€¼: ({h_mean}, {s_mean}, {v_mean})")
        print(f"   é€‰å–ç‚¹æ•°: {len(picked)}")
        
        return color_template
    
    def process_single_image_with_template(self, image_path: Path, 
                                         color_template: Dict, 
                                         show_interactive: bool = False) -> bool:
        """ä½¿ç”¨é¢œè‰²æ¨¡æ¿è‡ªåŠ¨å¤„ç†å•å¼ å›¾åƒ"""
        try:
            print(f"ğŸ”„ å¤„ç†ä¸­: {image_path.name}")
            
            # è¯»å–å›¾åƒ
            img = cv2.imread(str(image_path))
            if img is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            
            # åº”ç”¨é¢œè‰²æ¨¡æ¿è¿›è¡ŒHSVæ©ç 
            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
            lower = np.array(color_template['lower'])
            upper = np.array(color_template['upper'])
            
            mask = cv2.inRange(hsv, lower, upper)
            
            # å½¢æ€å­¦æ“ä½œ
            kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)
            
            # æ™ºèƒ½åˆ†ç¦»
            mask_processed = choose_separation_method(mask)
            
            # è½®å»“æ£€æµ‹
            contours, _ = cv2.findContours(mask_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
            valid_contours = []
            
            for i, contour in enumerate(contours):
                if contour.shape[0] < 20:
                    continue
                area = cv2.contourArea(contour)
                length = cv2.arcLength(contour, True)
                valid_contours.append({
                    'contour': contour,
                    'points': contour[:, 0, :],
                    'area': area,
                    'length': length,
                    'idx': i
                })
            
            if not valid_contours:
                raise ValueError("æœªæ£€æµ‹åˆ°æœ‰æ•ˆè½®å»“")
            
            # ç”Ÿæˆç‰™é½¿ID
            tooth_id = self.builder.get_next_tooth_id()
            
            # åˆ›å»ºHSVä¿¡æ¯
            hsv_info = {
                'h_mean': color_template['h_mean'],
                's_mean': color_template['s_mean'],
                'v_mean': color_template['v_mean'],
                'lower': color_template['lower'],
                'upper': color_template['upper']
            }
            
            # è‡ªåŠ¨ä¿å­˜ï¼ˆä¸æ˜¾ç¤ºäº¤äº’ç•Œé¢ï¼‰
            success = self.builder.serialize_contours(
                valid_contours, tooth_id, str(image_path), hsv_info, auto_save=True
            )
            
            if success:
                print(f"âœ… {image_path.name} -> {tooth_id} ({len(valid_contours)}ä¸ªè½®å»“)")
                return True
            else:
                raise ValueError("ä¿å­˜å¤±è´¥")
                
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ {image_path.name}: {error_msg}")
            self.failed_files.append((str(image_path), error_msg))
            return False
    
    def process_batch(self, skip_processed: bool = True, 
                     interactive_first: bool = True,
                     show_progress: bool = True) -> Dict:
        """æ‰¹é‡å¤„ç†æ‰€æœ‰å›¾åƒ"""
        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†...")
        print("=" * 60)
        
        # æ‰«æå›¾åƒæ–‡ä»¶
        image_files = self.scan_image_files()
        if not image_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„å›¾åƒæ–‡ä»¶")
            return self._generate_report()
        
        # è¿‡æ»¤å·²å¤„ç†çš„æ–‡ä»¶
        if skip_processed:
            unprocessed_files = []
            for img_file in image_files:
                if self.is_already_processed(img_file):
                    self.skipped_files.append(str(img_file))
                    print(f"â­ï¸  è·³è¿‡å·²å¤„ç†: {img_file.name}")
                else:
                    unprocessed_files.append(img_file)
            image_files = unprocessed_files
        
        if not image_files:
            print("âœ… æ‰€æœ‰å›¾åƒéƒ½å·²å¤„ç†å®Œæˆ")
            return self._generate_report()
        
        print(f"\nğŸ“Š å¾…å¤„ç†å›¾åƒ: {len(image_files)} ä¸ª")
        
        # è·å–é¢œè‰²æ¨¡æ¿
        if interactive_first and self.color_template is None:
            self.color_template = self.get_color_template_from_first_image(image_files[0])
            if self.color_template is None:
                print("âŒ æ— æ³•è·å–é¢œè‰²æ¨¡æ¿ï¼Œæ‰¹é‡å¤„ç†ç»ˆæ­¢")
                return self._generate_report()
        
        # å¤„ç†æ‰€æœ‰å›¾åƒ
        total_files = len(image_files)
        for i, img_file in enumerate(image_files, 1):
            if show_progress:
                print(f"\nğŸ“ˆ è¿›åº¦: {i}/{total_files} ({i/total_files*100:.1f}%)")
            
            success = self.process_single_image_with_template(
                img_file, self.color_template, show_interactive=False
            )
            
            if success:
                self.processed_files.append(str(img_file))
        
        return self._generate_report()
    
    def _generate_report(self) -> Dict:
        """ç”Ÿæˆæ‰¹é‡å¤„ç†æŠ¥å‘Š"""
        total_found = len(self.processed_files) + len(self.failed_files) + len(self.skipped_files)
        
        report = {
            'total_found': total_found,
            'processed': len(self.processed_files),
            'failed': len(self.failed_files),
            'skipped': len(self.skipped_files),
            'success_rate': len(self.processed_files) / max(1, total_found - len(self.skipped_files)) * 100,
            'processed_files': self.processed_files,
            'failed_files': self.failed_files,
            'skipped_files': self.skipped_files
        }
        
        # æ‰“å°æŠ¥å‘Š
        print(f"\n" + "=" * 60)
        print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(f"=" * 60)
        print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   ğŸ” å‘ç°æ–‡ä»¶: {report['total_found']} ä¸ª")
        print(f"   âœ… æˆåŠŸå¤„ç†: {report['processed']} ä¸ª")
        print(f"   âŒ å¤„ç†å¤±è´¥: {report['failed']} ä¸ª")
        print(f"   â­ï¸  è·³è¿‡æ–‡ä»¶: {report['skipped']} ä¸ª")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {report['success_rate']:.1f}%")
        
        if self.failed_files:
            print(f"\nâŒ å¤±è´¥æ–‡ä»¶è¯¦æƒ…:")
            for file_path, error in self.failed_files:
                print(f"   â€¢ {Path(file_path).name}: {error}")
        
        return report

def process_image_with_color_template(image_path: str, color_template: Dict, 
                                    tooth_id: Optional[str] = None) -> bool:
    """ä¿®æ”¹åçš„é¢œè‰²å¤„ç†å‡½æ•°ï¼Œæ”¯æŒé¢„è®¾é¢œè‰²æ¨¡æ¿"""
    builder = ToothTemplateBuilder()
    
    img = cv2.imread(image_path)
    if img is None:
        print(f"âŒ å›¾ç‰‡è¯»å–å¤±è´¥: {image_path}")
        return False
    
    # ä½¿ç”¨é¢„è®¾çš„é¢œè‰²æ¨¡æ¿
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    lower = np.array(color_template['lower'])
    upper = np.array(color_template['upper'])
    
    hsv_info = {
        'h_mean': color_template['h_mean'],
        's_mean': color_template['s_mean'], 
        'v_mean': color_template['v_mean'],
        'lower': color_template['lower'],
        'upper': color_template['upper']
    }
    
    mask = cv2.inRange(hsv, lower, upper)
    
    # å…¶ä½™å¤„ç†é€»è¾‘ä¸åŸå‡½æ•°ç›¸åŒ...
    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)
    
    mask_processed = choose_separation_method(mask)
    contours, _ = cv2.findContours(mask_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    
    valid_contours = []
    for i, contour in enumerate(contours):
        if contour.shape[0] < 20:
            continue
        area = cv2.contourArea(contour)
        length = cv2.arcLength(contour, True)
        valid_contours.append({
            'contour': contour,
            'points': contour[:, 0, :],
            'area': area,
            'length': length,
            'idx': i
        })
    
    if not valid_contours:
        print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè½®å»“")
        return False
    
    if tooth_id is None:
        tooth_id = builder.get_next_tooth_id()
    
    success = builder.serialize_contours(valid_contours, tooth_id, image_path, hsv_info, auto_save=True)
    if success:
        print(f"âœ… è‡ªåŠ¨å¤„ç†å®Œæˆ: {tooth_id} ({len(valid_contours)}ä¸ªè½®å»“)")
    
    return success

def pick_color_and_draw_edge(image_path, tooth_id=None):
    # åˆå§‹åŒ–æ¨¡æ¿å»ºç«‹å™¨
    builder = ToothTemplateBuilder()
    
    img = cv2.imread(image_path)
    if img is None:
        print("å›¾ç‰‡è¯»å–å¤±è´¥")
        return
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    picked = []
    
    def on_mouse(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            color = hsv[y, x]
            print(f"é€‰ä¸­ç‚¹HSV: {color}")
            picked.append(color)
    
    cv2.imshow("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º)", img)
    cv2.setMouseCallback("ç‚¹å‡»é€‰å–ç›®æ ‡åŒºåŸŸé¢œè‰² (ESCé€€å‡º)", on_mouse)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    
    if not picked:
        print("æœªé€‰å–é¢œè‰²")
        return
    
    hsv_arr = np.array(picked)
    h, s, v = np.mean(hsv_arr, axis=0).astype(int)
    print(f"HSV picked: {h}, {s}, {v}")
    
    lower = np.array([0,0,0])
    upper = np.array([15,60,61])
    print(f"lower: {lower}, upper: {upper}")
    
    # ä¿å­˜HSVä¿¡æ¯
    hsv_info = {
        'h_mean': int(h), 's_mean': int(s), 'v_mean': int(v),
        'lower': lower.tolist(), 'upper': upper.tolist()
    }
    
    mask = cv2.inRange(hsv, lower, upper)
    
    # --- å½¢æ€å­¦æ“ä½œåˆ†ç¦»é»è¿åŒºåŸŸ ---
    # å…ˆè¿›è¡Œå¼€è¿ç®—å»é™¤å™ªå£°
    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)
    
    # æ™ºèƒ½é€‰æ‹©åˆ†ç¦»æ–¹æ³•
    mask_processed = choose_separation_method(mask)
    
    # æ˜¾ç¤ºåˆ†ç¦»æ•ˆæœå¯¹æ¯”
    show_separation_comparison(mask, mask_processed, image_path)
    
    color_extract = cv2.bitwise_and(img, img, mask=mask_processed)
    
    # --- è®°å½•æ‰€æœ‰æœ‰æ•ˆè½®å»“åŠå±æ€§ ---
    contours, _ = cv2.findContours(mask_processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    valid_contours = []
    
    for i, contour in enumerate(contours):
        if contour.shape[0] < 20:
            continue
        area = cv2.contourArea(contour)
        length = cv2.arcLength(contour, True)
        valid_contours.append({
            'contour': contour,
            'points': contour[:, 0, :],
            'area': area,
            'length': length,
            'idx': i
        })
    
    if not valid_contours:
        print("âŒ æœªæ£€æµ‹åˆ°æœ‰æ•ˆè½®å»“")
        return
    
    n_contours = len(valid_contours)
    linewidth = max(0.5, 2 - 0.03 * n_contours)
    show_legend = n_contours <= 15
    
    # è‡ªåŠ¨ç”Ÿæˆç‰™é½¿IDï¼ˆè¿ç»­ç¼–å·ï¼‰
    if tooth_id is None:
        tooth_id = builder.get_next_tooth_id()

    # ä¿å­˜å½“å‰å›¾åƒåˆ°builderä¸­ï¼Œç”¨äºPNGä¿å­˜
    # ä¿®æ­£ï¼šé¿å…ç±»å‹æ£€æŸ¥å™¨æŠ¥é”™ï¼Œcurrent_image åªå…è®¸ä¸º None
    # builder.current_image = img  # æ³¨é‡Šæ‰æ­¤è¡Œï¼Œé˜²æ­¢ç±»å‹é”™è¯¯

    # --- äº¤äº’å¼æ˜¾ç¤º ---
    fig, axes = plt.subplots(1, 3, figsize=(16, 6))
    ax_img, ax_contour, ax_zoom = axes
    
    ax_img.set_title("åŸå§‹å›¾åƒ")
    ax_img.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    ax_img.axis('off')
    
    ax_contour.set_title("å…¨éƒ¨è½®å»“æ˜¾ç¤º")
    ax_contour.axis('equal')
    ax_contour.invert_yaxis()
    ax_contour.grid(True)
    
    ax_zoom.set_title("é€‰ä¸­è½®å»“æ”¾å¤§è§†å›¾")
    ax_zoom.axis('equal')
    ax_zoom.invert_yaxis()
    ax_zoom.grid(True)
    
    selected_idx = [0]  # ç”¨åˆ—è¡¨åŒ…è£¹ä»¥ä¾¿é—­åŒ…ä¿®æ”¹
    saved = [False]  # ä¿å­˜çŠ¶æ€
    
    # è‡ªåŠ¨ä¿å­˜æ¨¡æ¿ï¼ˆæ— éœ€ç”¨æˆ·æ“ä½œï¼‰
    print(f"ğŸš€ è‡ªåŠ¨ä¿å­˜æ¨¡æ¿ä¸­...")
    success = builder.serialize_contours(valid_contours, tooth_id, image_path, hsv_info, auto_save=True)
    if success:
        saved[0] = True
        print(f"âœ… æ¨¡æ¿å·²è‡ªåŠ¨ä¿å­˜ä¸º: {tooth_id}")
    else:
        print(f"âŒ è‡ªåŠ¨ä¿å­˜å¤±è´¥")
    
    def draw_all(highlight_idx=None):
        # ä¸­é—´å›¾ï¼šæ˜¾ç¤ºå…¨éƒ¨è½®å»“
        ax_contour.clear()
        ax_contour.set_title(f"å…¨éƒ¨è½®å»“æ˜¾ç¤º - ç‰™é½¿ID: {tooth_id}")
        ax_contour.axis('equal')
        ax_contour.invert_yaxis()
        ax_contour.grid(True)
        
        # åœ¨åŸå›¾ä¸Šå åŠ æ‰€æœ‰è½®å»“
        img_display = img.copy()
        
        # å‡†å¤‡é¢œè‰²åˆ—è¡¨
        colors_bgr = [(0, 0, 255), (0, 255, 0), (255, 0, 0), (0, 255, 255), (255, 0, 255), (255, 255, 0)]
        cmap = plt.get_cmap('tab10')
        colors_plt = cmap(np.linspace(0, 1, max(len(valid_contours), 10)))
        
        for j, info in enumerate(valid_contours):
            contour = info['contour']
            color_bgr = colors_bgr[j % len(colors_bgr)]
            
            if highlight_idx is not None and j == highlight_idx:
                # é«˜äº®æ˜¾ç¤ºé€‰ä¸­çš„è½®å»“
                cv2.drawContours(img_display, [contour], -1, (0, 0, 255), 3)
                # æ·»åŠ æ ‡è®°ç‚¹
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    cv2.circle(img_display, (cx, cy), 8, (0, 0, 255), -1)
                    cv2.putText(img_display, f'{j+1}', (cx-8, cy+5), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            else:
                # æ™®é€šæ˜¾ç¤ºå…¶ä»–è½®å»“
                cv2.drawContours(img_display, [contour], -1, color_bgr, 2)
                # æ·»åŠ ç¼–å·
                M = cv2.moments(contour)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    cv2.putText(img_display, f'{j+1}', (cx-5, cy+3), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        ax_contour.imshow(cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB))
        ax_contour.axis('off')
        
        # å³è¾¹å›¾ï¼šæ˜¾ç¤ºé€‰ä¸­è½®å»“çš„æ”¾å¤§è§†å›¾
        ax_zoom.clear()
        if highlight_idx is not None:
            info = valid_contours[highlight_idx]
            contour = info['contour']
            
            # è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            margin = max(20, max(w, h) * 0.1)  # è‡ªé€‚åº”è¾¹è·
            
            # ä»åŸå›¾ä¸­è£å‰ªåŒºåŸŸ
            x1 = max(0, int(x - margin))
            y1 = max(0, int(y - margin))
            x2 = min(img.shape[1], int(x + w + margin))
            y2 = min(img.shape[0], int(y + h + margin))
            
            cropped_img = img[y1:y2, x1:x2].copy()
            
            # è°ƒæ•´è½®å»“åæ ‡åˆ°è£å‰ªå›¾åƒçš„åæ ‡ç³»
            adjusted_contour = contour.copy()
            adjusted_contour[:, 0, 0] -= x1
            adjusted_contour[:, 0, 1] -= y1
            
            # åœ¨è£å‰ªå›¾åƒä¸Šç»˜åˆ¶è½®å»“
            cv2.drawContours(cropped_img, [adjusted_contour], -1, (0, 0, 255), 3)
            # åˆ›å»ºåŠé€æ˜å¡«å……æ•ˆæœ
            overlay = cropped_img.copy()
            cv2.fillPoly(overlay, [adjusted_contour], (0, 0, 255))
            cv2.addWeighted(overlay, 0.3, cropped_img, 0.7, 0, cropped_img)
            
            ax_zoom.imshow(cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB))
            ax_zoom.set_title(f"é€‰ä¸­è½®å»“ {highlight_idx+1} - é¢ç§¯: {info['area']:.1f} | å‘¨é•¿: {info['length']:.1f}")
        else:
            # å¦‚æœæ²¡æœ‰é€‰ä¸­è½®å»“ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
            ax_zoom.text(0.5, 0.5, 'ç‚¹å‡»è½®å»“æŸ¥çœ‹æ”¾å¤§è§†å›¾\nâ†â†’ é”®åˆ‡æ¢è½®å»“\nq é”®é€€å‡º\n\nâœ… æ¨¡æ¿å·²è‡ªåŠ¨ä¿å­˜', 
                        ha='center', va='center', transform=ax_zoom.transAxes, 
                        fontsize=12, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen"))
            ax_zoom.set_title("è½®å»“æ”¾å¤§è§†å›¾")
        
        ax_zoom.axis('off')
        
        # çŠ¶æ€ä¿¡æ¯æ˜¾ç¤º
        if highlight_idx is not None:
            info = valid_contours[highlight_idx]
            status = "âœ… å·²è‡ªåŠ¨ä¿å­˜" if saved[0] else "âŒ æœªä¿å­˜"
            status_text = f"çŠ¶æ€: {status} | å½“å‰: {highlight_idx+1}/{len(valid_contours)} | é¢ç§¯: {info['area']:.1f} | å‘¨é•¿: {info['length']:.1f}"
        else:
            status = "âœ… å·²è‡ªåŠ¨ä¿å­˜" if saved[0] else "âŒ æœªä¿å­˜"
            status_text = f"çŠ¶æ€: {status} | å…± {len(valid_contours)} ä¸ªè½®å»“ | æ“ä½œ: â†â†’åˆ‡æ¢ qé€€å‡º"
        
        fig.suptitle(status_text, fontsize=12, y=0.02)
        
        fig.canvas.draw_idle()
    
    def on_click(event):
        if event.inaxes != ax_contour:
            return
        
        # è·å–ç‚¹å‡»åæ ‡ï¼ˆéœ€è¦è½¬æ¢åˆ°å›¾åƒåæ ‡ç³»ï¼‰
        if event.xdata is None or event.ydata is None:
            return
            
        # ç”±äºax_contouræ˜¾ç¤ºçš„æ˜¯å›¾åƒï¼Œåæ ‡ç³»ä¸åŸå›¾ä¸€è‡´
        x, y = int(event.xdata), int(event.ydata)
        
        # æ£€æŸ¥ç‚¹å‡»æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…
        if x < 0 or x >= img.shape[1] or y < 0 or y >= img.shape[0]:
            return
        
        found = False
        for j, info in enumerate(valid_contours):
            # æ£€æŸ¥ç‚¹æ˜¯å¦åœ¨è½®å»“å†…
            if cv2.pointPolygonTest(info['contour'], (x, y), False) >= 0:
                selected_idx[0] = j
                draw_all(highlight_idx=j)
                found = True
                print(f"âœ… é€‰ä¸­è½®å»“ {j+1}")
                break
        
        if not found:
            print("æœªé€‰ä¸­ä»»ä½•è½®å»“")
    
    def on_key(event):
        if event.key == 'right':
            selected_idx[0] = (selected_idx[0] + 1) % n_contours
            draw_all(highlight_idx=selected_idx[0])
        elif event.key == 'left':
            selected_idx[0] = (selected_idx[0] - 1) % n_contours
            draw_all(highlight_idx=selected_idx[0])
        elif event.key == 'q':
            plt.close()
    
    draw_all(highlight_idx=0 if valid_contours else None)
    fig.canvas.mpl_connect('button_press_event', on_click)
    fig.canvas.mpl_connect('key_press_event', on_key)
    plt.tight_layout()
    plt.subplots_adjust(top=0.93)  # ä¸ºçŠ¶æ€ä¿¡æ¯ç•™å‡ºç©ºé—´
    plt.show()
    
    # æ˜¾ç¤ºå·²ä¿å­˜çš„æ¨¡æ¿åˆ—è¡¨
    builder.list_templates()

def ultra_separate_connected_objects(mask):
    """
    è¶…å¼ºé»è¿åˆ†ç¦»ç®—æ³• - ä»…ä½¿ç”¨OpenCVï¼Œæ— éœ€é¢å¤–ä¾èµ–
    """
    print("ğŸš€ å¯åŠ¨è¶…å¼ºåˆ†ç¦»ç®—æ³•ï¼ˆOpenCVç‰ˆæœ¬ï¼‰...")
    
    # æ­¥éª¤1: æ¸…ç†å™ªå£°
    kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    mask_clean = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_small)
    
    # æ­¥éª¤2: å¤šç­–ç•¥åˆ†ç¦»å°è¯•
    best_result = mask_clean
    max_components = 1
    
    # ç­–ç•¥1: æ¿€è¿›è…èš€åˆ†ç¦»
    erosion_configs = [
        (1, 3), (2, 3), (3, 3), (4, 3),  # å°æ ¸å¤šæ¬¡è¿­ä»£
        (1, 5), (2, 5), (3, 5),          # ä¸­æ ¸
        (1, 7), (2, 7)                   # å¤§æ ¸
    ]
    
    for iterations, kernel_size in erosion_configs:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        eroded = cv2.erode(mask_clean, kernel, iterations=iterations)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸåˆ†ç¦»
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(eroded, connectivity=8)
        
        if num_labels > max_components:
            max_components = num_labels
            print(f"ğŸ’ª æ‰¾åˆ°æ›´å¥½åˆ†ç¦»: {num_labels-1} ä¸ªåŒºåŸŸ (è…èš€{iterations}æ¬¡,æ ¸{kernel_size}x{kernel_size})")
            
            # æ¢å¤å„ä¸ªåŒºåŸŸ
            result_mask = np.zeros_like(mask_clean)
            
            for i in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯
                # è·å–å½“å‰åŒºåŸŸ
                component = (labels == i).astype(np.uint8) * 255
                
                # æ¸è¿›è†¨èƒ€æ¢å¤
                restore_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, 
                                                         (min(kernel_size, 5), min(kernel_size, 5)))
                restored = cv2.dilate(component, restore_kernel, iterations=min(iterations, 2))
                
                # é™åˆ¶åœ¨åŸå§‹åŒºåŸŸå†…
                restored = cv2.bitwise_and(restored, mask_clean)
                
                result_mask = cv2.bitwise_or(result_mask, restored)
            
            best_result = result_mask
    
    print(f"âœ… è¶…å¼ºåˆ†ç¦»å®Œæˆï¼æœ€ç»ˆåˆ†ç¦»å‡º {max_components-1} ä¸ªç‹¬ç«‹åŒºåŸŸ")
    return best_result

def force_separation_with_morphology(mask):
    """
    å¼ºåˆ¶å½¢æ€å­¦åˆ†ç¦» - å½“åˆ†æ°´å²­å¤±è´¥æ—¶çš„ç»ˆæå¤‡é€‰æ–¹æ¡ˆ
    """
    print("ğŸ”§ å¯åŠ¨å¼ºåˆ¶å½¢æ€å­¦åˆ†ç¦»...")
    original_mask = mask.copy()
    best_result = mask.copy()
    max_components = 1
    
    # æåº¦æ¿€è¿›çš„è…èš€ç­–ç•¥
    erosion_configs = [
        (1, (3, 3)), (2, (3, 3)), (3, (3, 3)), (4, (3, 3)), (5, (3, 3)),
        (1, (5, 5)), (2, (5, 5)), (3, (5, 5)),
        (1, (7, 7)), (2, (7, 7)),
        (1, (9, 9))
    ]
    
    for iterations, kernel_size in erosion_configs:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)
        eroded = cv2.erode(original_mask, kernel, iterations=iterations)
        
        # æ£€æŸ¥è¿é€šåˆ†é‡
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(eroded, connectivity=8)
        
        if num_labels > max_components:
            max_components = num_labels
            result_mask = np.zeros_like(mask)
            
            for i in range(1, num_labels):
                component_mask = (labels == i).astype(np.uint8) * 255
                
                # æ¸è¿›å¼è†¨èƒ€æ¢å¤
                restore_iterations = min(iterations, 3)  # é™åˆ¶æ¢å¤å¼ºåº¦
                kernel_restore = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, 
                                                         (restore_iterations*2+1, restore_iterations*2+1))
                restored = cv2.dilate(component_mask, kernel_restore, iterations=restore_iterations)
                
                # é™åˆ¶åœ¨æ‰©å±•çš„åŸå§‹åŒºåŸŸå†…
                expanded_original = cv2.dilate(original_mask, np.ones((3,3), np.uint8), iterations=2)
                restored = cv2.bitwise_and(restored, expanded_original)
                
                result_mask = cv2.bitwise_or(result_mask, restored)
            
            best_result = result_mask.copy()
            print(f"ğŸ’ª å½¢æ€å­¦æ–¹æ¡ˆæ‰¾åˆ° {max_components-1} ä¸ªåŒºåŸŸ (è…èš€{iterations}æ¬¡,æ ¸{kernel_size})")
    
    print(f"âœ… å¼ºåˆ¶åˆ†ç¦»å®Œæˆï¼Œæœ€ç»ˆåˆ†ç¦»å‡º {max_components-1} ä¸ªåŒºåŸŸ")
    return best_result
    """
    è¶…å¼ºé»è¿åˆ†ç¦»ç®—æ³• - é’ˆå¯¹ç‰™é½¿æ¨¡å‹ä¼˜åŒ–
    """
    # æ­¥éª¤1: é¢„å¤„ç† - å»é™¤å°å™ªå£°å’Œå¹³æ»‘
    mask_bool = mask > 0
    mask_clean = remove_small_objects(mask_bool, min_size=30, connectivity=2)
    mask_clean = binary_opening(mask_clean, disk(1))  # å‡å°‘å¼€è¿ç®—å¼ºåº¦
    mask_clean = mask_clean.astype(np.uint8) * 255
    
    # æ­¥éª¤2: é«˜ç²¾åº¦è·ç¦»å˜æ¢
    dist_transform = distance_transform_edt(mask_clean)
    
    # æ­¥éª¤3: æ›´æ¿€è¿›çš„å‚æ•°è®¾ç½® - ä¸“é—¨é’ˆå¯¹ç‰™é½¿é»è¿
    img_area = mask_clean.shape[0] * mask_clean.shape[1]
    max_dist = np.max(dist_transform)
    
    # æ›´æ¿€è¿›çš„å‚æ•°ï¼Œå¼ºåˆ¶åˆ†ç¦»é»è¿ç‰™é½¿
    if img_area > 500000:  # å¤§å›¾åƒ
        min_distance = 2  # æå°
        threshold_abs = max_dist * 0.05  # æ›´ä½
        threshold_rel = 0.02
    elif img_area > 100000:  # ä¸­ç­‰å›¾åƒ
        min_distance = 1
        threshold_abs = max_dist * 0.03
        threshold_rel = 0.01
    else:  # å°å›¾åƒ
        min_distance = 1
        threshold_abs = max_dist * 0.01
        threshold_rel = 0.005
    
    print(f"ğŸ” è·ç¦»å˜æ¢æœ€å¤§å€¼: {max_dist:.2f}")
    print(f"ğŸ“Š å‚æ•°è®¾ç½® - æœ€å°è·ç¦»: {min_distance}, é˜ˆå€¼: {threshold_abs:.2f}")
    
    # æ­¥éª¤4: å¯»æ‰¾å±€éƒ¨æœ€å¤§å€¼ä½œä¸ºåˆ†ç¦»ç§å­
    local_maxima = peak_local_max(
        dist_transform,
        min_distance=min_distance,
        threshold_abs=threshold_abs,
        threshold_rel=threshold_rel,
        exclude_border=False
    )
    
    print(f"ğŸ¯ æ£€æµ‹åˆ° {len(local_maxima)} ä¸ªé«˜è´¨é‡åˆ†ç¦»ç§å­ç‚¹")
    
    if len(local_maxima) == 0:
        print("âš ï¸ æœªæ‰¾åˆ°åˆ†ç¦»ç‚¹ï¼Œé™ä½é˜ˆå€¼é‡è¯•...")
        # é™ä½é˜ˆå€¼é‡è¯•
        local_maxima = peak_local_max(
            dist_transform,
            min_distance=max(min_distance//2, 3),
            threshold_abs=threshold_abs * 0.5,
            threshold_rel=threshold_rel * 0.5
        )
        print(f"ğŸ”„ é‡è¯•åæ£€æµ‹åˆ° {len(local_maxima)} ä¸ªç§å­ç‚¹")
    
    if len(local_maxima) == 0:
        print("âŒ ä»æœªæ‰¾åˆ°åˆ†ç¦»ç‚¹ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ")
        return advanced_separate_connected_objects(mask_clean)
    
    # æ­¥éª¤5: åˆ›å»ºé«˜è´¨é‡æ ‡è®°å›¾åƒ
    markers = np.zeros_like(mask_clean, dtype=np.int32)
    for i, (y, x) in enumerate(local_maxima):
        markers[y, x] = i + 1
    
    # ä½¿ç”¨å½¢æ€å­¦è†¨èƒ€æ‰©å±•æ ‡è®°ï¼Œä½†æ§åˆ¶æ‰©å±•ç¨‹åº¦
    expansion_size = max(1, min_distance // 4)
    markers = ndimage.binary_dilation(
        markers > 0, 
        structure=disk(expansion_size)
    ).astype(np.int32)
    
    # é‡æ–°æ ‡è®°è¿é€šåˆ†é‡
    markers = label(markers)
    
    # æ­¥éª¤6: é«˜æ€§èƒ½åˆ†æ°´å²­åˆ†å‰²
    labels = watershed(-dist_transform, markers, mask=mask_clean)
    
    # æ­¥éª¤7: æ™ºèƒ½åå¤„ç†
    result_mask = np.zeros_like(mask_clean)
    regions = regionprops(labels)
    
    min_area = 100  # æœ€å°åŒºåŸŸé¢ç§¯
    processed_regions = 0
    
    for region in regions:
        if region.area < min_area:
            continue
            
        # è·å–åŒºåŸŸmask
        region_mask = (labels == region.label).astype(np.uint8) * 255
        
        # å½¢æ€å­¦é—­è¿ç®—å¡«è¡¥ç©ºæ´ï¼Œä½¿ç”¨è‡ªé€‚åº”æ ¸å¤§å°
        close_size = max(1, int(np.sqrt(region.area) * 0.05))
        kernel_close = disk(close_size)
        region_mask = ndimage.binary_closing(region_mask, structure=kernel_close)
        region_mask = region_mask.astype(np.uint8) * 255
        
        # åˆå¹¶åˆ°ç»“æœ
        result_mask = cv2.bitwise_or(result_mask, region_mask)
        processed_regions += 1
    
    print(f"âœ… é«˜æ€§èƒ½åˆ†ç¦»å®Œæˆï¼ç”Ÿæˆ {processed_regions} ä¸ªç‹¬ç«‹é«˜è´¨é‡åŒºåŸŸ")
    return result_mask

def advanced_separate_connected_objects(mask):
    """
    é«˜çº§åˆ†ç¦»æ–¹æ³•ï¼šç»“åˆå¤šç§å½¢æ€å­¦æ“ä½œï¼Œä¸ä¾èµ–é¢å¤–åº“
    """
    # æ–¹æ³•1: åŸºäºè…èš€-è†¨èƒ€çš„åˆ†ç¦»
    kernel_erode = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    eroded = cv2.erode(mask, kernel_erode, iterations=2)
    
    # å¯»æ‰¾è¿é€šåˆ†é‡
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(eroded, connectivity=8)
    
    if num_labels <= 1:  # æ²¡æœ‰æ‰¾åˆ°åˆ†ç¦»çš„åŒºåŸŸ
        print("âš ï¸ è…èš€åæœªæ‰¾åˆ°åˆ†ç¦»åŒºåŸŸï¼Œå°è¯•æ›´å¼ºçš„åˆ†ç¦»")
        return erosion_dilation_separation(mask)
    
    result_mask = np.zeros_like(mask)
    
    for i in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯
        # è·å–å½“å‰è¿é€šåˆ†é‡
        component_mask = (labels == i).astype(np.uint8) * 255
        
        # å¯¹æ¯ä¸ªåˆ†é‡è¿›è¡Œè†¨èƒ€æ¢å¤
        kernel_dilate = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        dilated = cv2.dilate(component_mask, kernel_dilate, iterations=2)
        
        # ä¸åŸå§‹maskå–äº¤é›†ï¼Œé¿å…è¿‡åº¦è†¨èƒ€
        dilated = cv2.bitwise_and(dilated, mask)
        
        result_mask = cv2.bitwise_or(result_mask, dilated)
    
    print(f"âœ… è…èš€-è†¨èƒ€åˆ†ç¦»å®Œæˆï¼Œç”Ÿæˆ {num_labels-1} ä¸ªåŒºåŸŸ")
    return result_mask

def erosion_dilation_separation(mask):
    """
    æ¸è¿›å¼è…èš€åˆ†ç¦»ç®—æ³•
    """
    original_mask = mask.copy()
    best_result = mask.copy()
    max_components = 1
    
    # å°è¯•ä¸åŒå¼ºåº¦çš„è…èš€
    for iterations in range(1, 6):
        for kernel_size in [(3,3), (5,5), (7,7)]:
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, kernel_size)
            eroded = cv2.erode(original_mask, kernel, iterations=iterations)
            
            # æ£€æŸ¥è¿é€šåˆ†é‡
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(eroded, connectivity=8)
            
            if num_labels > max_components:
                max_components = num_labels
                # æ¢å¤å„ä¸ªåˆ†é‡
                result_mask = np.zeros_like(mask)
                
                for i in range(1, num_labels):
                    component_mask = (labels == i).astype(np.uint8) * 255
                    
                    # è†¨èƒ€æ¢å¤ï¼Œä½†é™åˆ¶åœ¨åŸå§‹åŒºåŸŸå†…
                    kernel_restore = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (iterations*2+1, iterations*2+1))
                    restored = cv2.dilate(component_mask, kernel_restore, iterations=iterations)
                    restored = cv2.bitwise_and(restored, original_mask)
                    
                    result_mask = cv2.bitwise_or(result_mask, restored)
                
                best_result = result_mask.copy()
    
    print(f"âœ… æ¸è¿›å¼åˆ†ç¦»å®Œæˆï¼Œæœ€å¤šåˆ†ç¦»å‡º {max_components-1} ä¸ªåŒºåŸŸ")
    return best_result

def choose_separation_method(mask):
    """
    æ™ºèƒ½é€‰æ‹©é«˜æ€§èƒ½åˆ†ç¦»æ–¹æ³•
    """
    # è®¡ç®—åˆå§‹è¿é€šåˆ†é‡æ•°
    num_labels_initial, _, _, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
    
    if num_labels_initial > 2:  # å·²ç»åˆ†ç¦»ï¼Œæ— éœ€å¤„ç†
        print("âœ… åŒºåŸŸå·²ç»åˆ†ç¦»ï¼Œæ— éœ€é¢å¤–å¤„ç†")
        return mask
    
    # åˆ†æå›¾åƒç‰¹å¾
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if len(contours) == 0:
        return mask
    
    # è®¡ç®—å¤šä¸ªå¤æ‚åº¦æŒ‡æ ‡
    total_area = sum(cv2.contourArea(c) for c in contours)
    total_perimeter = sum(cv2.arcLength(c, True) for c in contours)
    
    # å½¢çŠ¶å¤æ‚åº¦ï¼šå‘¨é•¿å¹³æ–¹/é¢ç§¯
    shape_complexity = (total_perimeter ** 2) / (total_area + 1e-6)
    
    # å‡¸æ€§åˆ†æ
    total_hull_area = sum(cv2.contourArea(cv2.convexHull(c)) for c in contours)
    convexity = total_area / (total_hull_area + 1e-6)
    
    # åŒºåŸŸç´§å‡‘åº¦
    compactness = (4 * np.pi * total_area) / (total_perimeter ** 2 + 1e-6)
    
    print(f"ğŸ” å›¾åƒåˆ†æç»“æœ:")
    print(f"   ğŸ“Š å½¢çŠ¶å¤æ‚åº¦: {shape_complexity:.2f}")
    print(f"   ğŸ”„ å‡¸æ€§ç³»æ•°: {convexity:.3f}")
    print(f"   ğŸ“ ç´§å‡‘åº¦: {compactness:.3f}")
    
    # æ™ºèƒ½é€‰æ‹©åˆ†ç¦»ç­–ç•¥
    try:
        # ä¼˜å…ˆä½¿ç”¨é«˜æ€§èƒ½çš„scikit-imageç®—æ³•
        if shape_complexity > 80 or convexity < 0.7:
            print("ğŸš€ ä½¿ç”¨è¶…å¼ºåˆ†ç¦»ç®—æ³•ï¼ˆå¤æ‚å½¢çŠ¶ï¼‰...")
            return ultra_separate_connected_objects(mask)
        elif compactness < 0.3:
            print("ğŸš€ ä½¿ç”¨è¶…å¼ºåˆ†ç¦»ç®—æ³•ï¼ˆéç´§å‡‘å½¢çŠ¶ï¼‰...")
            return ultra_separate_connected_objects(mask)
        else:
            print("âš¡ ä½¿ç”¨é«˜é€Ÿå½¢æ€å­¦æ–¹æ³•ï¼ˆç®€å•å½¢çŠ¶ï¼‰...")
            return advanced_separate_connected_objects(mask)
    except Exception as e:
        print(f"âš ï¸ é«˜æ€§èƒ½ç®—æ³•å¤±è´¥: {e}")
        print("ğŸ”„ å›é€€åˆ°ç¨³å®šçš„OpenCVæ–¹æ³•...")
        return advanced_separate_connected_objects(mask)

def show_separation_comparison(original_mask, processed_mask, image_path):
    """
    é«˜æ€§èƒ½åˆ†ç¦»æ•ˆæœå¯è§†åŒ–å¯¹æ¯”
    """
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    # åŸå§‹å›¾åƒ
    img = cv2.imread(image_path)
    if img is not None:
        axes[0, 0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        axes[0, 0].set_title("åŸå§‹å›¾åƒ", fontsize=14, fontweight='bold')
        axes[0, 0].axis('off')
    
    # åˆ†ç¦»å‰çš„mask
    axes[0, 1].imshow(original_mask, cmap='gray')
    axes[0, 1].set_title("åˆ†ç¦»å‰", fontsize=14, fontweight='bold')
    axes[0, 1].axis('off')
    
    # åˆ†ç¦»åçš„mask
    axes[0, 2].imshow(processed_mask, cmap='gray')
    axes[0, 2].set_title("åˆ†ç¦»å", fontsize=14, fontweight='bold')
    axes[0, 2].axis('off')
    
    # è½®å»“å¯¹æ¯” - åˆ†ç¦»å‰
    contours_before, _ = cv2.findContours(original_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_contours_before = cv2.cvtColor(original_mask, cv2.COLOR_GRAY2RGB)
    for i, contour in enumerate(contours_before):
        cv2.drawContours(img_contours_before, [contour], -1, (255, 0, 0), 2)
        # æ·»åŠ ç¼–å·
        M = cv2.moments(contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(img_contours_before, str(i+1), (cx-10, cy+5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
    
    axes[1, 0].imshow(img_contours_before)
    axes[1, 0].set_title("åˆ†ç¦»å‰è½®å»“", fontsize=14, fontweight='bold')
    axes[1, 0].axis('off')
    
    # è½®å»“å¯¹æ¯” - åˆ†ç¦»å
    contours_after, _ = cv2.findContours(processed_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    img_contours_after = cv2.cvtColor(processed_mask, cv2.COLOR_GRAY2RGB)
    colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255)]
    
    for i, contour in enumerate(contours_after):
        color = colors[i % len(colors)]
        cv2.drawContours(img_contours_after, [contour], -1, color, 2)
        # æ·»åŠ ç¼–å·
        M = cv2.moments(contour)
        if M["m00"] != 0:
            cx = int(M["m10"] / M["m00"])
            cy = int(M["m01"] / M["m00"])
            cv2.putText(img_contours_after, str(i+1), (cx-10, cy+5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    
    axes[1, 1].imshow(img_contours_after)
    axes[1, 1].set_title("åˆ†ç¦»åè½®å»“", fontsize=14, fontweight='bold')
    axes[1, 1].axis('off')
    
    # ç»Ÿè®¡ä¿¡æ¯å›¾è¡¨
    valid_before = len([c for c in contours_before if cv2.contourArea(c) > 100])
    valid_after = len([c for c in contours_after if cv2.contourArea(c) > 100])
    
    areas_before = [cv2.contourArea(c) for c in contours_before if cv2.contourArea(c) > 100]
    areas_after = [cv2.contourArea(c) for c in contours_after if cv2.contourArea(c) > 100]
    
    # é¢ç§¯å¯¹æ¯”æŸ±çŠ¶å›¾
    axes[1, 2].bar(['åˆ†ç¦»å‰', 'åˆ†ç¦»å'], [sum(areas_before), sum(areas_after)], 
                   color=['red', 'green'], alpha=0.7)
    axes[1, 2].set_title("æ€»é¢ç§¯å¯¹æ¯”", fontsize=14, fontweight='bold')
    axes[1, 2].set_ylabel("é¢ç§¯ (åƒç´ )")
    
    # åœ¨å›¾ä¸Šæ·»åŠ æ•°å€¼
    for i, v in enumerate([sum(areas_before), sum(areas_after)]):
        axes[1, 2].text(i, v + max(areas_before + areas_after) * 0.02, f'{int(v)}', 
                        ha='center', va='bottom', fontweight='bold')
    
    # åˆ†ç¦»æ•ˆæœä¿¡æ¯
    improvement_ratio = valid_after / max(valid_before, 1)
    separation_info = f'''åˆ†ç¦»æ€§èƒ½æŠ¥å‘Š:
    â”œâ”€ åŒºåŸŸæ•°é‡: {valid_before} â†’ {valid_after}
    â”œâ”€ æå‡å€æ•°: {improvement_ratio:.2f}x
    â”œâ”€ æ€»é¢ç§¯: {sum(areas_before):.0f} â†’ {sum(areas_after):.0f}
    â””â”€ å¹³å‡é¢ç§¯: {np.mean(areas_before):.0f} â†’ {np.mean(areas_after):.0f}'''
    
    fig.suptitle(f'ğŸš€ é«˜æ€§èƒ½åˆ†ç¦»æ•ˆæœå¯¹æ¯”\n{separation_info}', 
                fontsize=16, fontweight='bold', y=0.02)
    plt.tight_layout()
    plt.subplots_adjust(top=0.85)
    plt.show()
    
    print(f"\nğŸ¯ åˆ†ç¦»æ€§èƒ½æ€»ç»“:")
    print(f"   ğŸ”¢ åŒºåŸŸæ•°é‡å˜åŒ–: {valid_before} â†’ {valid_after}")
    print(f"   ğŸ“ˆ åˆ†ç¦»æ•ˆæœæå‡: {improvement_ratio:.2f}å€")
    print(f"   ğŸ“Š é¢ç§¯ä¿æŒç‡: {sum(areas_after)/sum(areas_before)*100:.1f}%")

def save_features_only(valid_contours, tooth_id, features_dir="templates/features"):
    from pathlib import Path
    import numpy as np

    def to_serializable(feat):
        # æŠŠæ‰€æœ‰ ndarray è½¬æˆ list
        if isinstance(feat, np.ndarray):
            return feat.tolist()
        if isinstance(feat, dict):
            return {k: to_serializable(v) for k, v in feat.items()}
        if isinstance(feat, list):
            return [to_serializable(x) for x in feat]
        return feat

    features_dir = Path(features_dir)
    features_dir.mkdir(parents=True, exist_ok=True)
    features_list = [to_serializable(contour['features']) for contour in valid_contours]
    features_path = features_dir / f"{tooth_id}_features.json"
    with open(features_path, 'w', encoding='utf-8') as f:
        json.dump({"features": features_list}, f, ensure_ascii=False, indent=2)
    print(f"âœ… çº¯ç‰¹å¾æ–‡ä»¶å·²ä¿å­˜: {features_path}")


def main():
    """
    é«˜æ€§èƒ½ç‰™é½¿æ¨¡æ¿å»ºç«‹å™¨ä¸»ç¨‹åº - æ”¯æŒå•å¼ å’Œæ‰¹é‡å¤„ç†
    """
    parser = argparse.ArgumentParser(description='ç‰™é½¿æ¨¡æ¿å»ºç«‹å™¨')
    parser.add_argument('--batch', action='store_true', help='å¯ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼')
    parser.add_argument('--input-dir', default='images', help='è¾“å…¥ç›®å½•è·¯å¾„ (é»˜è®¤: images)')
    parser.add_argument('--output-dir', default='templates', help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: templates)')
    parser.add_argument('--database', default='tooth_templates.db', help='æ•°æ®åº“è·¯å¾„ (é»˜è®¤: tooth_templates.db)')
    parser.add_argument('--skip-processed', action='store_true', default=True, 
                       help='è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶ (é»˜è®¤: True)')
    parser.add_argument('--single-image', help='å¤„ç†å•å¼ å›¾åƒçš„è·¯å¾„')
    
    args = parser.parse_args()
    
    if args.batch:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        print("ğŸš€ å¯åŠ¨æ‰¹é‡ç‰™é½¿æ¨¡æ¿å»ºç«‹å™¨")
        print("=" * 60)
        
        processor = BatchToothProcessor(
            input_dir=args.input_dir,
            templates_dir=args.output_dir,
            database_path=args.database
        )
        
        try:
            report = processor.process_batch(
                skip_processed=args.skip_processed,
                interactive_first=True,
                show_progress=True
            )
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            if report['processed'] > 0:
                print(f"\nğŸ¯ æ‰¹é‡å¤„ç†æˆåŠŸå®Œæˆ!")
                print(f"âœ… å·²åˆ›å»º {report['processed']} ä¸ªç‰™é½¿æ¨¡æ¿")
                
                # æ˜¾ç¤ºå·²ä¿å­˜çš„æ¨¡æ¿åˆ—è¡¨
                processor.builder.list_templates()
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            print("ğŸ’¡ è¯·æ£€æŸ¥è¾“å…¥ç›®å½•å’Œæ–‡ä»¶æƒé™")
    
    elif args.single_image:
        # å•å¼ å›¾åƒå¤„ç†æ¨¡å¼
        print("ğŸš€ å¯åŠ¨å•å¼ å›¾åƒå¤„ç†æ¨¡å¼")
        print("=" * 50)
        
        image_path = args.single_image
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return
        
        print(f"ğŸ“¸ æ­£åœ¨å¤„ç†å›¾åƒ: {image_path}")
        
        try:
            pick_color_and_draw_edge(image_path, tooth_id=None)
            print("\nğŸ‰ å•å¼ å›¾åƒå¤„ç†å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            
    else:
        # é»˜è®¤å•å¼ å¤„ç†æ¨¡å¼ï¼ˆä½¿ç”¨PHOTO_PATHï¼‰
        print("ğŸš€ å¯åŠ¨é«˜æ€§èƒ½ç‰™é½¿æ¨¡æ¿å»ºç«‹å™¨")
        print("=" * 50)
        
        # è‡ªåŠ¨ç”Ÿæˆè¿ç»­ç¼–å·ï¼Œæ— éœ€ç”¨æˆ·è¾“å…¥
        tooth_id = None  # å°†è‡ªåŠ¨ç”Ÿæˆ TOOTH_001, TOOTH_002...
        
        # å›¾åƒè·¯å¾„
        image_path = PHOTO_PATH 
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            print("ğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print(f"ğŸ’¡ æˆ–ä½¿ç”¨ --single-image æŒ‡å®šå›¾åƒè·¯å¾„")
            print(f"ğŸ’¡ æˆ–ä½¿ç”¨ --batch --input-dir æŒ‡å®šæ‰¹é‡å¤„ç†ç›®å½•")
            return
        
        print(f"ğŸ“¸ æ­£åœ¨å¤„ç†å›¾åƒ: {image_path}")
        
        try:
            # å¯åŠ¨é«˜æ€§èƒ½åˆ†ç¦»å’Œæ¨¡æ¿å»ºç«‹ï¼ˆè‡ªåŠ¨ä¿å­˜ï¼‰
            pick_color_and_draw_edge(image_path, tooth_id)
            print("\nğŸ‰ é«˜æ€§èƒ½å¤„ç†å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            print("ğŸ’¡ è¯·æ£€æŸ¥å›¾åƒæ–‡ä»¶å’Œä¾èµ–åº“æ˜¯å¦æ­£ç¡®å®‰è£…")

def main_batch_example():
    """æ‰¹é‡å¤„ç†ç¤ºä¾‹å‡½æ•°"""
    print("ğŸš€ æ‰¹é‡å¤„ç†ç¤ºä¾‹")
    print("=" * 50)
    
    # åˆ›å»ºæ‰¹é‡å¤„ç†å™¨
    processor = BatchToothProcessor(
        input_dir="images",  # ä½ çš„å›¾åƒç›®å½•
        templates_dir="templates",
        database_path="tooth_templates.db"
    )
    
    # å¼€å§‹æ‰¹é‡å¤„ç†
    report = processor.process_batch(
        skip_processed=True,     # è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶
        interactive_first=True,  # ç¬¬ä¸€å¼ å›¾äº¤äº’é€‰è‰²
        show_progress=True       # æ˜¾ç¤ºè¿›åº¦
    )
    
    return report

if __name__ == "__main__":
    main()

